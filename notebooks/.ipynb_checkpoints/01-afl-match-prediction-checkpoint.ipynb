{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138f86c8-e133-4fd3-a020-d1241f679c6e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project predicts Australian Football League (AFL) match outcomes using machine learning techniques. The dataset was scraped using the fitzRoy package from Footywire and covers detailed player statistics and match information spanning 10 seasons from 2015 to 2025.\n",
    "\n",
    "With rich game-level and player-level data, including player performance metrics and match results, the project builds predictive models to forecast match winners and analyze key factors influencing game outcomes.\n",
    "\n",
    "**Goal: Develop an accurate and interpretable model to predict AFL match results.**\n",
    "\n",
    "# 1. Exploratory Data Analysis\n",
    "\n",
    "**Imports**\n",
    "\n",
    "I'll import the core libraries needed for data handling, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "6a6569d5-df41-4ba1-97ce-d6517548092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pointbiserialr\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e82b6c-3cbc-4277-9513-a2591016bfef",
   "metadata": {},
   "source": [
    "I'll load the data that was scraped from footywire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "398a3b3b-4cb2-4294-9b63-58b0cb7f312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player stats data\n",
    "stats_2015 = pd.read_csv('../data/footywire_player_stats_2015.csv')\n",
    "stats_2016 = pd.read_csv('../data/footywire_player_stats_2016.csv')\n",
    "stats_2017 = pd.read_csv('../data/footywire_player_stats_2017.csv')\n",
    "stats_2018 = pd.read_csv('../data/footywire_player_stats_2018.csv')\n",
    "stats_2019 = pd.read_csv('../data/footywire_player_stats_2019.csv')\n",
    "stats_2020 = pd.read_csv('../data/footywire_player_stats_2020.csv')\n",
    "stats_2021 = pd.read_csv('../data/footywire_player_stats_2021.csv')\n",
    "stats_2022 = pd.read_csv('../data/footywire_player_stats_2022.csv')\n",
    "stats_2023 = pd.read_csv('../data/footywire_player_stats_2023.csv')\n",
    "stats_2024 = pd.read_csv('../data/footywire_player_stats_2024.csv')\n",
    "stats_2025 = pd.read_csv('../data/footywire_player_stats_2025.csv')\n",
    "\n",
    "# Game results data\n",
    "games_2015 = pd.read_csv('../data/footywire_match_results_2015.csv')\n",
    "games_2016 = pd.read_csv('../data/footywire_match_results_2016.csv')\n",
    "games_2017 = pd.read_csv('../data/footywire_match_results_2017.csv')\n",
    "games_2018 = pd.read_csv('../data/footywire_match_results_2018.csv')\n",
    "games_2019 = pd.read_csv('../data/footywire_match_results_2019.csv')\n",
    "games_2020 = pd.read_csv('../data/footywire_match_results_2020.csv')\n",
    "games_2021 = pd.read_csv('../data/footywire_match_results_2021.csv')\n",
    "games_2022 = pd.read_csv('../data/footywire_match_results_2022.csv')\n",
    "games_2023 = pd.read_csv('../data/footywire_match_results_2023.csv')\n",
    "games_2024 = pd.read_csv('../data/footywire_match_results_2024.csv')\n",
    "games_2025 = pd.read_csv('../data/footywire_match_results_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "6da2f3f7-6416-41b3-87d1-136c2082c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the yearly datasets into two dataframes representing every year \n",
    "stats = pd.concat([stats_2015, stats_2016, stats_2017, stats_2018, stats_2019, stats_2020, stats_2021, stats_2022, stats_2023, stats_2024, stats_2025], ignore_index=True)\n",
    "games = pd.concat([games_2015, games_2016, games_2017, games_2018, games_2019, games_2020, games_2021, games_2022, games_2023, games_2024, games_2025], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345fdfe6-8104-4c65-bbff-668a20f64a6f",
   "metadata": {},
   "source": [
    "**Data Inspection – Games Dataset**\n",
    "\n",
    "Date (Datetime) – The date the match was played.\n",
    "\n",
    "Time (Nominal) – The scheduled start time of the match (24-hour format).\n",
    "\n",
    "Round (Nominal) – The round or week of the competition (e.g., “Round 1”).\n",
    "\n",
    "Venue (Nominal) – The stadium where the match took place.\n",
    "\n",
    "Home.Team (Nominal) – The team playing as the home side.\n",
    "\n",
    "Away.Team (Nominal) – The team playing as the away side.\n",
    "\n",
    "Home.Points (Numeric) – The total points scored by the home team in that match.\n",
    "\n",
    "Away.Points (Numeric) – The total points scored by the away team in that match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "84d09e36-7191-491f-ab48-fbde508e5d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Home.Team</th>\n",
       "      <th>Away.Team</th>\n",
       "      <th>Home.Points</th>\n",
       "      <th>Away.Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>19:20</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>78</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>13:40</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>115</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>16:35</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>Accor Stadium</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Essendon</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>18:20</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>Gabba</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>19:20</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>Marvel Stadium</td>\n",
       "      <td>Western Bulldogs</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>97</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time    Round            Venue         Home.Team    Away.Team  \\\n",
       "0  2015-04-02  19:20  Round 1              MCG           Carlton     Richmond   \n",
       "1  2015-04-04  13:40  Round 1              MCG         Melbourne   Gold Coast   \n",
       "2  2015-04-04  16:35  Round 1    Accor Stadium            Sydney     Essendon   \n",
       "3  2015-04-04  18:20  Round 1            Gabba          Brisbane  Collingwood   \n",
       "4  2015-04-04  19:20  Round 1   Marvel Stadium  Western Bulldogs   West Coast   \n",
       "\n",
       "   Home.Points  Away.Points  \n",
       "0           78          105  \n",
       "1          115           89  \n",
       "2           72           60  \n",
       "3           74           86  \n",
       "4           97           87  "
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "09537e60-ccba-4b53-988a-5a7f0e42f168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Home.Team</th>\n",
       "      <th>Away.Team</th>\n",
       "      <th>Home.Points</th>\n",
       "      <th>Away.Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>2025-07-25</td>\n",
       "      <td>19:50</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>ENGIE Stadium</td>\n",
       "      <td>GWS</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>102</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>13:20</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>People First Stadium</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>130</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>14:15</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>126</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>19:35</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Marvel Stadium</td>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>49</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>19:40</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Adelaide Oval</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>133</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time     Round                  Venue        Home.Team  \\\n",
       "2205  2025-07-25  19:50  Round 20          ENGIE Stadium              GWS   \n",
       "2206  2025-07-26  13:20  Round 20   People First Stadium       Gold Coast   \n",
       "2207  2025-07-26  14:15  Round 20          Optus Stadium        Fremantle   \n",
       "2208  2025-07-26  19:35  Round 20         Marvel Stadium  North Melbourne   \n",
       "2209  2025-07-26  19:40  Round 20          Adelaide Oval         Adelaide   \n",
       "\n",
       "          Away.Team  Home.Points  Away.Points  \n",
       "2205         Sydney          102           58  \n",
       "2206       Brisbane          130           64  \n",
       "2207     West Coast          126           77  \n",
       "2208        Geelong           49          150  \n",
       "2209  Port Adelaide          133           35  "
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ade11-f02c-47ab-af24-57530c7eee24",
   "metadata": {},
   "source": [
    "I’ll start with a quick, high-level review of the dataset to gauge its completeness and variety, while also checking for potential issues such as duplicates or anomalies, before moving on to more detailed analysis and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "39bbfef7-d6dd-415d-b276-b8ec2d0737d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2210, 8)\n",
      "\n",
      "Data types:\n",
      "Date           object\n",
      "Time           object\n",
      "Round          object\n",
      "Venue          object\n",
      "Home.Team      object\n",
      "Away.Team      object\n",
      "Home.Points     int64\n",
      "Away.Points     int64\n",
      "dtype: object\n",
      "\n",
      "Total missing values: 0\n",
      "Duplicate rows: 0\n",
      "Unique Venues: 25\n",
      "Unique Teams: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home.Points</th>\n",
       "      <th>Away.Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2210.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>85.533484</td>\n",
       "      <td>79.432127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.258423</td>\n",
       "      <td>25.130338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>205.000000</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Home.Points  Away.Points\n",
       "count  2210.000000  2210.000000\n",
       "mean     85.533484    79.432127\n",
       "std      26.258423    25.130338\n",
       "min      16.000000    14.000000\n",
       "25%      67.000000    62.000000\n",
       "50%      84.000000    78.000000\n",
       "75%     103.000000    95.000000\n",
       "max     205.000000   173.000000"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "print(f\"Shape: {games.shape}\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "print(games.dtypes)\n",
    "\n",
    "# Total missing values\n",
    "total_missing = games.isna().sum().sum()\n",
    "print(f\"\\nTotal missing values: {total_missing}\")\n",
    "\n",
    "# Duplicate rows\n",
    "duplicate_count = games.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Unique venue count\n",
    "print(f\"Unique Venues: {games['Venue'].nunique()}\")\n",
    "\n",
    "# Unique team count\n",
    "print(f\"Unique Teams: {games['Home.Team'].nunique()}\")\n",
    "\n",
    "games.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dbac20-471b-4af5-bda9-f5d818aca25c",
   "metadata": {},
   "source": [
    "Home advantage is evident, with home teams scoring an average of 85.5 points compared to 79.4 points for away teams.\n",
    "\n",
    "Date and time information can be used to calculate the rest period each team had before a match, which may influence performance.\n",
    "\n",
    "Potential features for the predictive model include each team’s historical win rate at specific venues and the exact number of rest days between matches.\n",
    "\n",
    "The representation of finals within the Round column will also be reviewed to ensure it is handled appropriately during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "1e418199-c0db-4a2e-841c-db59fe365cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Round 1', 'Round 2', 'Round 3', 'Round 4', 'Round 5', 'Round 6',\n",
       "       'Round 7', 'Round 8', 'Round 9', 'Round 10', 'Round 11',\n",
       "       'Round 12', 'Round 13', 'Round 14', 'Round 15', 'Round 16',\n",
       "       'Round 17', 'Round 18', 'Round 19', 'Round 20', 'Round 21',\n",
       "       'Round 22', 'Round 23', 'Qualifying Final', 'Elimination Final',\n",
       "       'Semi Final', 'Preliminary Final', 'Grand Final',\n",
       "       'Preliminary Finals', 'Round 24', 'Round 0'], dtype=object)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all unique rounds\n",
    "games['Round'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df3cfa-7e8b-4870-a202-7d7c911e079d",
   "metadata": {},
   "source": [
    "The Round values will be converted to integers during the data cleaning stage to enable calculations based on the number of previous rounds a team has played.\n",
    "\n",
    "**Data Inspection (Stats)**\n",
    "\n",
    "The stats dataset contains variables describing player performance and match details in AFL games:\n",
    "\n",
    "Date (Datetime) – Date when the match was played.\n",
    "\n",
    "Season (Numeric) – Year of the AFL season.\n",
    "\n",
    "Round (Numeric) – Round number within the season.\n",
    "\n",
    "Venue (Nominal) – Stadium where the match took place.\n",
    "\n",
    "Player (Nominal) – Name of the player.\n",
    "\n",
    "Team (Nominal) – Player’s team.\n",
    "\n",
    "Opposition (Nominal) – Opposing team in the match.\n",
    "\n",
    "Status (Nominal) – Home or away status of the player’s team.\n",
    "\n",
    "Match_id (Nominal) – Unique identifier for each match.\n",
    "\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "GA (Numeric) – Goal assists.\n",
    "\n",
    "CP (Numeric) – Contested possessions gained.\n",
    "\n",
    "UP (Numeric) – Uncontested possessions gained.\n",
    "\n",
    "ED (Numeric) – Effective disposals (successful passes).\n",
    "\n",
    "DE (Numeric) – Disposal efficiency.\n",
    "\n",
    "CM (Numeric) – Centre clearances won.\n",
    "\n",
    "MI5 (Numeric) – Disposals gaining more than 5 meters.\n",
    "\n",
    "One.Percenters (Numeric) – Defensive efforts like spoils or smothers.\n",
    "\n",
    "BO (Numeric) – Number of bounces while running.\n",
    "\n",
    "TOG (Numeric) – Time on ground (minutes played).\n",
    "\n",
    "K (Numeric) – Kicks delivered.\n",
    "\n",
    "HB (Numeric) – Handballs delivered.\n",
    "\n",
    "D (Numeric) – Total disposals (kicks + handballs).\n",
    "\n",
    "M (Numeric) – Marks (catches from kicks).\n",
    "\n",
    "G (Numeric) – Goals scored by the player.\n",
    "\n",
    "B (Numeric) – Behinds scored.\n",
    "\n",
    "T (Numeric) – Tackles made.\n",
    "\n",
    "HO (Numeric) – Hitouts in ruck contests.\n",
    "\n",
    "I50 (Numeric) – Inside 50-meter entries.\n",
    "\n",
    "CL (Numeric) – Clearances from stoppages.\n",
    "\n",
    "CG (Numeric) – Clangers.\n",
    "\n",
    "R50 (Numeric) – Rebound 50-meter exits.\n",
    "\n",
    "FF (Numeric) – Free kicks awarded to player’s team.\n",
    "\n",
    "FA (Numeric) – Free kicks against player’s team.\n",
    "\n",
    "AF (Numeric) – AFL fantasy.\n",
    "\n",
    "SC (Numeric) – Super coach.\n",
    "\n",
    "CCL (Numeric) – Centre clearances.\n",
    "\n",
    "SCL (Numeric) – Score clearances.\n",
    "\n",
    "SI (Numeric) – Spoils preventing opponent marks.\n",
    "\n",
    "MG (Numeric) – Meters gained from disposals.\n",
    "\n",
    "TO (Numeric) – Turnovers conceded.\n",
    "\n",
    "ITC (Numeric) – Intercepts made.\n",
    "\n",
    "T5 (Numeric) – Times among top 5 possessions on team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "01000ee7-2a5d-4c34-ad5d-1fbef0d03252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opposition</th>\n",
       "      <th>Status</th>\n",
       "      <th>Match_id</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>FA</th>\n",
       "      <th>AF</th>\n",
       "      <th>SC</th>\n",
       "      <th>CCL</th>\n",
       "      <th>SCL</th>\n",
       "      <th>SI</th>\n",
       "      <th>MG</th>\n",
       "      <th>TO</th>\n",
       "      <th>ITC</th>\n",
       "      <th>T5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Bryce Gibbs</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Home</td>\n",
       "      <td>5964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Tom Bell</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Home</td>\n",
       "      <td>5964</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Sam Docherty</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Home</td>\n",
       "      <td>5964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Chris Judd</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Home</td>\n",
       "      <td>5964</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>Round 1</td>\n",
       "      <td>MCG</td>\n",
       "      <td>Kade Simpson</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Home</td>\n",
       "      <td>5964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Season    Round Venue        Player     Team Opposition Status  \\\n",
       "0  2015-04-02    2015  Round 1   MCG   Bryce Gibbs  Carlton   Richmond   Home   \n",
       "1  2015-04-02    2015  Round 1   MCG      Tom Bell  Carlton   Richmond   Home   \n",
       "2  2015-04-02    2015  Round 1   MCG  Sam Docherty  Carlton   Richmond   Home   \n",
       "3  2015-04-02    2015  Round 1   MCG    Chris Judd  Carlton   Richmond   Home   \n",
       "4  2015-04-02    2015  Round 1   MCG  Kade Simpson  Carlton   Richmond   Home   \n",
       "\n",
       "   Match_id   GA  ...   FA     AF     SC  CCL  SCL    SI     MG   TO   ITC  \\\n",
       "0      5964  0.0  ...  2.0   96.0   82.0  2.0  2.0   8.0  466.0  6.0   3.0   \n",
       "1      5964  2.0  ...  0.0  108.0  115.0  0.0  1.0  10.0  475.0  4.0   1.0   \n",
       "2      5964  1.0  ...  0.0  107.0  147.0  0.0  2.0   6.0  287.0  2.0  12.0   \n",
       "3      5964  4.0  ...  2.0   93.0  108.0  4.0  2.0   8.0  474.0  5.0   2.0   \n",
       "4      5964  0.0  ...  0.0   97.0  103.0  0.0  0.0   4.0  269.0  4.0   5.0   \n",
       "\n",
       "    T5  \n",
       "0  0.0  \n",
       "1  3.0  \n",
       "2  1.0  \n",
       "3  1.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "193bff30-06f1-4872-a260-44305407a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opposition</th>\n",
       "      <th>Status</th>\n",
       "      <th>Match_id</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>FA</th>\n",
       "      <th>AF</th>\n",
       "      <th>SC</th>\n",
       "      <th>CCL</th>\n",
       "      <th>SCL</th>\n",
       "      <th>SI</th>\n",
       "      <th>MG</th>\n",
       "      <th>TO</th>\n",
       "      <th>ITC</th>\n",
       "      <th>T5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99263</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>2025</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>Sandy Brock</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Away</td>\n",
       "      <td>11357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99264</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>2025</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>Jobe Shanahan</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Away</td>\n",
       "      <td>11357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99265</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>2025</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>Matt Owies</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Away</td>\n",
       "      <td>11357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99266</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>2025</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>Tyrell Dewar</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Away</td>\n",
       "      <td>11357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99267</th>\n",
       "      <td>2025-07-26</td>\n",
       "      <td>2025</td>\n",
       "      <td>Round 20</td>\n",
       "      <td>Optus Stadium</td>\n",
       "      <td>Archer Reid</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Away</td>\n",
       "      <td>11357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Season     Round          Venue         Player        Team  \\\n",
       "99263  2025-07-26    2025  Round 20  Optus Stadium    Sandy Brock  West Coast   \n",
       "99264  2025-07-26    2025  Round 20  Optus Stadium  Jobe Shanahan  West Coast   \n",
       "99265  2025-07-26    2025  Round 20  Optus Stadium     Matt Owies  West Coast   \n",
       "99266  2025-07-26    2025  Round 20  Optus Stadium   Tyrell Dewar  West Coast   \n",
       "99267  2025-07-26    2025  Round 20  Optus Stadium    Archer Reid  West Coast   \n",
       "\n",
       "      Opposition Status  Match_id   GA  ...   FA    AF    SC  CCL  SCL   SI  \\\n",
       "99263  Fremantle   Away     11357  0.0  ...  0.0  30.0  41.0  0.0  0.0  2.0   \n",
       "99264  Fremantle   Away     11357  0.0  ...  0.0  34.0  15.0  0.0  0.0  1.0   \n",
       "99265  Fremantle   Away     11357  0.0  ...  0.0  16.0  25.0  0.0  0.0  0.0   \n",
       "99266  Fremantle   Away     11357  0.0  ...  0.0  15.0  10.0  0.0  0.0  1.0   \n",
       "99267  Fremantle   Away     11357  0.0  ...  0.0   7.0  13.0  0.0  0.0  0.0   \n",
       "\n",
       "          MG   TO  ITC   T5  \n",
       "99263  163.0  1.0  1.0  0.0  \n",
       "99264   10.0  3.0  0.0  1.0  \n",
       "99265    7.0  0.0  1.0  1.0  \n",
       "99266   50.0  0.0  0.0  0.0  \n",
       "99267    1.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f2d225-db2e-48cd-b5b8-f08e85762b84",
   "metadata": {},
   "source": [
    "I will perform the same high-level overview on the stats dataframe as was done for the games dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "8b4c3c2f-a34c-41aa-8de3-84ee882f78da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (99268, 42)\n",
      "\n",
      "Data types:\n",
      "Date               object\n",
      "Season              int64\n",
      "Round              object\n",
      "Venue              object\n",
      "Player             object\n",
      "Team               object\n",
      "Opposition         object\n",
      "Status             object\n",
      "Match_id            int64\n",
      "GA                float64\n",
      "CP                float64\n",
      "UP                float64\n",
      "ED                float64\n",
      "DE                float64\n",
      "CM                float64\n",
      "MI5               float64\n",
      "One.Percenters    float64\n",
      "BO                float64\n",
      "TOG               float64\n",
      "K                 float64\n",
      "HB                float64\n",
      "D                 float64\n",
      "M                 float64\n",
      "G                 float64\n",
      "B                 float64\n",
      "T                 float64\n",
      "HO                float64\n",
      "I50               float64\n",
      "CL                float64\n",
      "CG                float64\n",
      "R50               float64\n",
      "FF                float64\n",
      "FA                float64\n",
      "AF                float64\n",
      "SC                float64\n",
      "CCL               float64\n",
      "SCL               float64\n",
      "SI                float64\n",
      "MG                float64\n",
      "TO                float64\n",
      "ITC               float64\n",
      "T5                float64\n",
      "dtype: object\n",
      "\n",
      "Total missing values: 13101\n",
      "Duplicate rows: 0\n",
      "Unique Players: 2724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Match_id</th>\n",
       "      <th>GA</th>\n",
       "      <th>CP</th>\n",
       "      <th>UP</th>\n",
       "      <th>ED</th>\n",
       "      <th>DE</th>\n",
       "      <th>CM</th>\n",
       "      <th>MI5</th>\n",
       "      <th>One.Percenters</th>\n",
       "      <th>...</th>\n",
       "      <th>FA</th>\n",
       "      <th>AF</th>\n",
       "      <th>SC</th>\n",
       "      <th>CCL</th>\n",
       "      <th>SCL</th>\n",
       "      <th>SI</th>\n",
       "      <th>MG</th>\n",
       "      <th>TO</th>\n",
       "      <th>ITC</th>\n",
       "      <th>T5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99268.000000</td>\n",
       "      <td>99268.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "      <td>98871.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2020.003606</td>\n",
       "      <td>9618.381754</td>\n",
       "      <td>0.370715</td>\n",
       "      <td>6.117962</td>\n",
       "      <td>9.851321</td>\n",
       "      <td>11.727595</td>\n",
       "      <td>72.127812</td>\n",
       "      <td>0.474558</td>\n",
       "      <td>0.507874</td>\n",
       "      <td>2.094537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835007</td>\n",
       "      <td>68.396365</td>\n",
       "      <td>73.764774</td>\n",
       "      <td>0.533857</td>\n",
       "      <td>1.103043</td>\n",
       "      <td>4.034793</td>\n",
       "      <td>250.858958</td>\n",
       "      <td>3.003044</td>\n",
       "      <td>3.021432</td>\n",
       "      <td>0.480576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.156504</td>\n",
       "      <td>1708.871716</td>\n",
       "      <td>0.660685</td>\n",
       "      <td>3.681863</td>\n",
       "      <td>5.261543</td>\n",
       "      <td>5.768292</td>\n",
       "      <td>14.813611</td>\n",
       "      <td>0.844474</td>\n",
       "      <td>0.968909</td>\n",
       "      <td>2.331714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980024</td>\n",
       "      <td>27.363854</td>\n",
       "      <td>29.673155</td>\n",
       "      <td>1.062050</td>\n",
       "      <td>1.537628</td>\n",
       "      <td>2.620106</td>\n",
       "      <td>146.658719</td>\n",
       "      <td>2.018134</td>\n",
       "      <td>2.609266</td>\n",
       "      <td>0.845519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>5964.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>9458.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>10259.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>73.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>10815.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>11394.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1169.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Season      Match_id            GA            CP            UP  \\\n",
       "count  99268.000000  99268.000000  98871.000000  98871.000000  98871.000000   \n",
       "mean    2020.003606   9618.381754      0.370715      6.117962      9.851321   \n",
       "std        3.156504   1708.871716      0.660685      3.681863      5.261543   \n",
       "min     2015.000000   5964.000000      0.000000      0.000000      0.000000   \n",
       "25%     2017.000000   9458.000000      0.000000      4.000000      6.000000   \n",
       "50%     2020.000000  10259.000000      0.000000      5.000000      9.000000   \n",
       "75%     2023.000000  10815.000000      1.000000      8.000000     13.000000   \n",
       "max     2025.000000  11394.000000      6.000000     32.000000     37.000000   \n",
       "\n",
       "                 ED            DE            CM           MI5  One.Percenters  \\\n",
       "count  98871.000000  98871.000000  98871.000000  98871.000000    98871.000000   \n",
       "mean      11.727595     72.127812      0.474558      0.507874        2.094537   \n",
       "std        5.768292     14.813611      0.844474      0.968909        2.331714   \n",
       "min        0.000000      0.000000      0.000000      0.000000        0.000000   \n",
       "25%        7.000000     63.600000      0.000000      0.000000        0.000000   \n",
       "50%       11.000000     73.300000      0.000000      0.000000        1.000000   \n",
       "75%       15.000000     82.100000      1.000000      1.000000        3.000000   \n",
       "max       45.000000    100.000000      9.000000     12.000000       25.000000   \n",
       "\n",
       "       ...            FA            AF            SC           CCL  \\\n",
       "count  ...  98871.000000  98871.000000  98871.000000  98871.000000   \n",
       "mean   ...      0.835007     68.396365     73.764774      0.533857   \n",
       "std    ...      0.980024     27.363854     29.673155      1.062050   \n",
       "min    ...      0.000000     -6.000000    -12.000000      0.000000   \n",
       "25%    ...      0.000000     49.000000     53.000000      0.000000   \n",
       "50%    ...      1.000000     67.000000     72.000000      0.000000   \n",
       "75%    ...      1.000000     86.000000     93.000000      1.000000   \n",
       "max    ...      9.000000    200.000000    229.000000     12.000000   \n",
       "\n",
       "                SCL            SI            MG            TO           ITC  \\\n",
       "count  98871.000000  98871.000000  98871.000000  98871.000000  98871.000000   \n",
       "mean       1.103043      4.034793    250.858958      3.003044      3.021432   \n",
       "std        1.537628      2.620106    146.658719      2.018134      2.609266   \n",
       "min        0.000000      0.000000    -92.000000      0.000000      0.000000   \n",
       "25%        0.000000      2.000000    143.000000      2.000000      1.000000   \n",
       "50%        1.000000      4.000000    229.000000      3.000000      2.000000   \n",
       "75%        2.000000      6.000000    338.000000      4.000000      4.000000   \n",
       "max       14.000000     21.000000   1169.000000     17.000000     22.000000   \n",
       "\n",
       "                 T5  \n",
       "count  98871.000000  \n",
       "mean       0.480576  \n",
       "std        0.845519  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        9.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "print(f\"Shape: {stats.shape}\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "print(stats.dtypes)\n",
    "\n",
    "# Total missing values\n",
    "total_missing = stats.isna().sum().sum()\n",
    "print(f\"\\nTotal missing values: {total_missing}\")\n",
    "\n",
    "# Duplicate rows\n",
    "duplicate_count = stats.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Unique player count\n",
    "print(f\"Unique Players: {stats['Player'].nunique()}\")\n",
    "\n",
    "stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32721fe3-8e55-4d6b-8b02-8f4065198eb6",
   "metadata": {},
   "source": [
    "I will develop a formula to calculate offensive and defensive ratings for each player, weighting individual statistics according to their relative importance. These ratings will then be aggregated at the team level to generate an overall team rating, which I anticipate will be a highly predictive feature.\n",
    "\n",
    "The dataset contains 13,101 missing values, which will need to be addressed. Additionally, the number of unique players appears unusually high for a 10-year period (~13,000), whereas domain knowledge suggests it should be closer to 1,800. This discrepancy warrants further investigation.\n",
    "\n",
    "# 1.1 Cleaning the Data\n",
    "\n",
    "**Missing Values**\n",
    "\n",
    "I'll examine the missing values in the stats dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "0daf774c-cde6-4686-932c-96276a03294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              159\n",
       "Season              5\n",
       "Round              28\n",
       "Venue              17\n",
       "Player            231\n",
       "Team               18\n",
       "Opposition         18\n",
       "Status              2\n",
       "Match_id          301\n",
       "GA                  0\n",
       "CP                  0\n",
       "UP                  0\n",
       "ED                  0\n",
       "DE                  0\n",
       "CM                  0\n",
       "MI5                 0\n",
       "One.Percenters      0\n",
       "BO                  0\n",
       "TOG                 0\n",
       "K                   0\n",
       "HB                  0\n",
       "D                   0\n",
       "M                   0\n",
       "G                   0\n",
       "B                   0\n",
       "T                   0\n",
       "HO                  0\n",
       "I50                 0\n",
       "CL                  0\n",
       "CG                  0\n",
       "R50                 0\n",
       "FF                  0\n",
       "FA                  0\n",
       "AF                  0\n",
       "SC                  0\n",
       "CCL                 0\n",
       "SCL                 0\n",
       "SI                  0\n",
       "MG                  0\n",
       "TO                  0\n",
       "ITC                 0\n",
       "T5                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals = stats[stats.isna().any(axis=1)]\n",
    "missing_vals.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2554a-dc67-44e7-b08f-ddf3cef3034e",
   "metadata": {},
   "source": [
    "These missing rows can be removed, as they are distributed across multiple years, teams, and rounds. This dispersion ensures there is no large consecutive block of missing data that could adversely impact model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "3e385cf5-f20e-4685-960f-13dec08e377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "Season            0\n",
       "Round             0\n",
       "Venue             0\n",
       "Player            0\n",
       "Team              0\n",
       "Opposition        0\n",
       "Status            0\n",
       "Match_id          0\n",
       "GA                0\n",
       "CP                0\n",
       "UP                0\n",
       "ED                0\n",
       "DE                0\n",
       "CM                0\n",
       "MI5               0\n",
       "One.Percenters    0\n",
       "BO                0\n",
       "TOG               0\n",
       "K                 0\n",
       "HB                0\n",
       "D                 0\n",
       "M                 0\n",
       "G                 0\n",
       "B                 0\n",
       "T                 0\n",
       "HO                0\n",
       "I50               0\n",
       "CL                0\n",
       "CG                0\n",
       "R50               0\n",
       "FF                0\n",
       "FA                0\n",
       "AF                0\n",
       "SC                0\n",
       "CCL               0\n",
       "SCL               0\n",
       "SI                0\n",
       "MG                0\n",
       "TO                0\n",
       "ITC               0\n",
       "T5                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats.dropna()\n",
    "stats.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07690f1-cc84-4626-b5dd-8623389debea",
   "metadata": {},
   "source": [
    "**Player Count**\n",
    "\n",
    "As noted earlier, the dataset contains 2,724 unique players, which appears excessive for a 10-year period. This will be investigated further to confirm its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "18b6ed9e-8d56-4710-a75b-623d0775e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bryce Gibbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Bell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sam Docherty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Judd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kade Simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>Ben Jepson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>Daniel Rioli  ↗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>Leo Lombard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>Zac Banch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>Sam Marshall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2723 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "0         Bryce Gibbs\n",
       "1            Tom Bell\n",
       "2        Sam Docherty\n",
       "3          Chris Judd\n",
       "4        Kade Simpson\n",
       "...               ...\n",
       "2718       Ben Jepson\n",
       "2719  Daniel Rioli  ↗\n",
       "2720      Leo Lombard\n",
       "2721        Zac Banch\n",
       "2722     Sam Marshall\n",
       "\n",
       "[2723 rows x 1 columns]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats['Player'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799ff91-b446-413d-b2e2-1a10e5cdd0f7",
   "metadata": {},
   "source": [
    "There is an arrow symbol next to Daniel Rioli’s name, which likely indicates that he was subbed on during the game. Such characters will need to be removed, as they create duplicates of the same player name. Since I plan to aggregate the average statistics for each player, it is important to retain the data from matches where players were subbed on or off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "f3d3498d-413d-4708-a403-1e430ef890af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1537"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any characters from 'Player' names that are unusual\n",
    "# Then strip leading/trailing whitespace\n",
    "stats['Player'] = stats['Player'].str.replace(r\"[^\\w\\s'-]\", '', regex=True).str.strip()\n",
    "\n",
    "# Count the number of unique player names\n",
    "stats['Player'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc55a75-8319-4107-ac04-b26729a41e97",
   "metadata": {},
   "source": [
    "This revised number appears to be more reasonable.\n",
    "\n",
    "**Irrelevant Columns**\n",
    "\n",
    "The AFL Fantasy and SuperCoach columns in the stats data will be dropped, as they are derived from other statistics already present in the dataset. Since I plan to calculate my own player rating based on these underlying statistics, these columns do not add value to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "3efcfae6-1a07-4468-8a93-f5ac1ad99ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.drop(columns=['AF', 'SC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9fcc30-096a-4254-ba19-eacc9415d5d6",
   "metadata": {},
   "source": [
    "**Winner Column**\n",
    "\n",
    "A new column indicating the winner of each game will be required to facilitate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "94fedaaf-a334-4148-9900-30410af0881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag if the home team won (1) or not (0)\n",
    "games['HomeWin'] = (games['Home.Points'] > games['Away.Points']).astype(int)\n",
    "\n",
    "# Flag if the away team won (1) or not (0)\n",
    "games['AwayWin'] = (games['Away.Points'] > games['Home.Points']).astype(int)\n",
    "\n",
    "# Determine the winner's name, or 'Draw' if points are equal\n",
    "games['Winner'] = np.where(games['HomeWin'], games['Home.Team'],\n",
    "                           np.where(games['AwayWin'], games['Away.Team'], 'Draw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f4039-e529-4057-8f03-a91404339c6a",
   "metadata": {},
   "source": [
    "**Season and Match_id**\n",
    "\n",
    "Columns indicating the current season and the match_id in the games dataframe are required to enable merging with the stats dataframe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "abfd0c9e-29c0-4855-b965-72971ee237ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' to datetime and extract 'Season'\n",
    "games['Date'] = pd.to_datetime(games['Date'])\n",
    "games['Season'] = games['Date'].dt.year\n",
    "\n",
    "# Prepare stats subset for merging (rename 'Team' to 'Home.Team')\n",
    "merge_stats = stats[['Match_id', 'Round', 'Team', 'Season']].rename(columns={'Team': 'Home.Team'})\n",
    "\n",
    "# Merge, drop duplicates, and reset index\n",
    "games = games.merge(merge_stats, on=['Round', 'Home.Team', 'Season']).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c28b0-471a-4ddd-bb9d-32369f4d18fe",
   "metadata": {},
   "source": [
    "**Finals and Rounds**\n",
    "\n",
    "The Round column will be converted to a numeric identifier to enable easier processing in later stages of analysis. Finals rounds will be standardized to match the regular season format by mapping them to rounds 25, 26, 27 and 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "b57ca261-0b5c-4e3d-bc50-0f32630e30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map finals round names to numeric values\n",
    "finals_map = {\n",
    "    'Qualifying Final': 25,\n",
    "    'Elimination Final': 25,\n",
    "    'Semi Final': 26,\n",
    "    'Preliminary Final': 27,\n",
    "    'Preliminary Finals': 27,\n",
    "    'Grand Final': 28\n",
    "}\n",
    "\n",
    "# Apply finals mapping and convert 'Round' in games to integers\n",
    "games['Round'] = games['Round'].replace(finals_map)\n",
    "games['Round'] = games['Round'].replace(r'Round (\\d+)', r'\\1', regex=True).astype(int)\n",
    "\n",
    "# Apply finals mapping and convert 'Round' in stats to integers\n",
    "stats['Round'] = stats['Round'].replace(finals_map)\n",
    "stats['Round'] = stats['Round'].replace(r'Round (\\d+)', r'\\1', regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef5a2f-4b50-4803-b355-b2437553cf57",
   "metadata": {},
   "source": [
    "**Start Time Categories**\n",
    "\n",
    "To better explore the relationship between game start time and match outcomes, I will categorize each game into one of three distinct time bins: Afternoon, Evening, and Night. This classification will provide a clearer structure for analysis and make it easier to identify potential patterns or trends related to the timing of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "04149f67-7299-45b2-967e-d59afca0928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour (as integer) from the 'Time' column formatted as HH:MM\n",
    "hour = games['Time'].str.split(':').str[0].astype(int)\n",
    "\n",
    "# Categorise each game into 'Afternoon', 'Evening', or 'Night' based on start time\n",
    "#   - Afternoon: 00:00–14:59\n",
    "#   - Evening: 15:00–17:59\n",
    "#   - Night: 18:00–23:59\n",
    "games['TimeCategory'] = pd.cut(\n",
    "    hour,\n",
    "    bins=[0, 15, 18, 24],\n",
    "    labels=['Afternoon', 'Evening', 'Night'],\n",
    "    right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d8763-bf15-4db7-bcb3-0f2244820772",
   "metadata": {},
   "source": [
    "# 1.2 Feature Exploration\n",
    "\n",
    "**Game Start Time**\n",
    "\n",
    "I will investigate whether the scheduled start time of a game has a measurable impact on the likelihood of a team winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "180871ed-ebce-498d-beb5-da8c0af17f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Team, Chi2, p_value]\n",
       "Index: []"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store chi-squared test results for each team\n",
    "results = []\n",
    "\n",
    "# Loop through every unique team in the dataset\n",
    "for team in games['Home.Team'].unique():\n",
    "    \n",
    "    # Filter games where the current team was either home or away\n",
    "    team_df = games[(games['Home.Team'] == team) | (games['Away.Team'] == team)].copy()\n",
    "    \n",
    "    # Create a binary column: 1 if the team won, 0 if they lost\n",
    "    team_df['Won'] = (team_df['Winner'] == team).astype(int)\n",
    "    \n",
    "    # Group by time category and count wins and total matches\n",
    "    # observed=False ensures that all categories (Afternoon, Evening, Night) are kept, even if absent\n",
    "    team_df = team_df.groupby('TimeCategory', as_index=False, observed=False).agg({\n",
    "        'Won': 'sum', \n",
    "        'Match_id': 'count'\n",
    "    })\n",
    "\n",
    "    # Calculate losses as total matches minus wins\n",
    "    team_df['Lost'] = team_df['Match_id'] - team_df['Won']\n",
    "    \n",
    "    # Prepare the contingency table for chi-squared test (TimeCategory x Won/Lost)\n",
    "    contingency_table = team_df.drop(columns='Match_id').set_index('TimeCategory')\n",
    "\n",
    "    # Perform chi-squared test of independence\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "    \n",
    "    # Store results with Bonferroni correction (multiply p-value by number of tests = 18 teams)\n",
    "    results.append({'Team': team, 'Chi2': chi2, 'p_value': p * 18})\n",
    "\n",
    "# Convert results to DataFrame and sort by adjusted p-value\n",
    "results = pd.DataFrame(results).sort_values(by='p_value')\n",
    "\n",
    "# Filter for teams with statistically significant home advantage (p < 0.05)\n",
    "results[results['p_value'] < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc5da4-67ee-4eae-b064-f9f225f0a96a",
   "metadata": {},
   "source": [
    "There’s no statistically significant evidence that start time affects the likelihood of winning for any individual team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8afe7c3-bbda-49f3-91b4-db10d79e2523",
   "metadata": {},
   "source": [
    "**Home Team Advantage**\n",
    "\n",
    "I will investigate whether playing at home has any influence on the outcome of the winner for each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "5659ef37-6548-422b-821b-521fe7851dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Chi2</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>14.791755</td>\n",
       "      <td>0.002161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Coast</td>\n",
       "      <td>12.847620</td>\n",
       "      <td>0.006082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Geelong</td>\n",
       "      <td>11.951127</td>\n",
       "      <td>0.009831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>11.125652</td>\n",
       "      <td>0.015326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Richmond</td>\n",
       "      <td>9.608302</td>\n",
       "      <td>0.034866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Team       Chi2   p_value\n",
       "14  Gold Coast  14.791755  0.002161\n",
       "9   West Coast  12.847620  0.006082\n",
       "15     Geelong  11.951127  0.009831\n",
       "8     Hawthorn  11.125652  0.015326\n",
       "10    Richmond   9.608302  0.034866"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store results for each team\n",
    "results = []\n",
    "\n",
    "# Loop through every unique team in the dataset\n",
    "for team in games['Home.Team'].unique():\n",
    "    \n",
    "    # Filter games where the current team was either home or away\n",
    "    team_df = games[(games['Home.Team'] == team) | (games['Away.Team'] == team)].copy()\n",
    "        \n",
    "    # Create a binary column: 1 if the team won, 0 if they lost\n",
    "    team_df['Won'] = (team_df['Winner'] == team).astype(int)\n",
    "    \n",
    "    # Label each game as 'Home' or 'Away' for the current team\n",
    "    team_df['Location'] = np.where(team_df['Home.Team'] == team, 'Home', 'Away')\n",
    "    \n",
    "    # Aggregate wins and total games by location\n",
    "    team_df = team_df.groupby('Location', as_index=False, observed=False)[['Won', 'Match_id']].agg({\n",
    "        'Won': 'sum', \n",
    "        'Match_id': 'count'\n",
    "    })\n",
    "    \n",
    "    # Calculate losses as total games minus wins\n",
    "    team_df['Lost'] = team_df['Match_id'] - team_df['Won']\n",
    "    \n",
    "    # Prepare contingency table with wins and losses indexed by location\n",
    "    contingency_table = team_df.drop(columns='Match_id').set_index('Location')\n",
    "    \n",
    "    # Perform Chi-squared test to see if win/loss depends on location\n",
    "    chi2, p, _, _ = chi2_contingency(contingency_table)\n",
    "        \n",
    "    # Store results and apply Bonferroni correction for multiple tests\n",
    "    results.append({'Team': team, 'Chi2': chi2, 'p_value': p * 18})\n",
    "\n",
    "# Convert results to DataFrame and sort by adjusted p-value\n",
    "results = pd.DataFrame(results).sort_values(by='p_value')\n",
    "\n",
    "# Filter for teams with statistically significant home advantage (p < 0.05)\n",
    "results[results['p_value'] < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352adc2-ae51-445e-bb7a-3ea5292d6712",
   "metadata": {},
   "source": [
    "Only five teams—Gold Coast, West Coast, Geelong, Hawthorn, and Richmond—show a statistically significant home advantage after Bonferroni correction, with p-values below 0.05. Their Chi-squared statistics highlight a notable deviation from the “no home advantage” expectation, while all other teams show no strong evidence of an advantage at home. Overall, there is a small but meaningful home team effect in the AFL. \n",
    "\n",
    "To account for shared stadiums, I will calculate each team’s win rate at a venue based on their last five games, capturing both home advantage and away disadvantage. Teams with exclusive grounds, like Gold Coast and Geelong, naturally exhibit stronger home advantage.\n",
    "\n",
    "This function calculates each team’s recent form at the venue by computing their win rate over the last five games played there. It captures both home advantage and away disadvantage, giving a more precise measure of performance at each stadium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f9c7c3b-9c90-43c8-b696-6ab097d8529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_5_venue(matchid, home_team, away_team, games):\n",
    "    # Get the venue of the current game\n",
    "    venue = games.loc[games['Match_id'] == matchid, 'Venue'].values[0]\n",
    "\n",
    "    # Filter all games involving either team at that venue\n",
    "    venue_games = games[((games['Home.Team'] == home_team) | (games['Away.Team'] == home_team) |\n",
    "                         (games['Home.Team'] == away_team) | (games['Away.Team'] == away_team)) &\n",
    "                        (games['Venue'] == venue)].copy()\n",
    "    \n",
    "    venue_games = venue_games.sort_values(['Season', 'Round'])\n",
    "    \n",
    "    # Get last 5 games at venue for home team (excluding current)\n",
    "    home_venue_games = venue_games[((venue_games['Home.Team'] == home_team) | (venue_games['Away.Team'] == home_team)) &\n",
    "                                   (venue_games['Match_id'] != matchid)].tail(5)\n",
    "    \n",
    "    # Get last 5 games at venue for away team (excluding current)\n",
    "    away_venue_games = venue_games[((venue_games['Home.Team'] == away_team) | (venue_games['Away.Team'] == away_team)) &\n",
    "                                   (venue_games['Match_id'] != matchid)].tail(5)\n",
    "    \n",
    "    # Calculate win rates\n",
    "    home_wins = ((home_venue_games['Home.Team'] == home_team) & (home_venue_games['HomeWin'] == 1)) | \\\n",
    "                ((home_venue_games['Away.Team'] == home_team) & (home_venue_games['AwayWin'] == 1))\n",
    "    away_wins = ((away_venue_games['Home.Team'] == away_team) & (away_venue_games['HomeWin'] == 1)) | \\\n",
    "                ((away_venue_games['Away.Team'] == away_team) & (away_venue_games['AwayWin'] == 1))\n",
    "    \n",
    "    home_winrate = home_wins.astype(int).mean() if not home_venue_games.empty else 0.0\n",
    "    away_winrate = away_wins.astype(int).mean() if not away_venue_games.empty else 0.0\n",
    "    \n",
    "    return [home_winrate, away_winrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5bd13-8483-4247-b62a-09f94910b141",
   "metadata": {},
   "source": [
    "This function adds each team’s venue win rates as new columns for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bd90e8bc-e4ec-4e9f-93e9-48c84bec92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_venue_columns(games: pd.DataFrame, years) -> pd.DataFrame:\n",
    "    games_subset = games[games['Season'].isin(years)].copy()\n",
    "\n",
    "    # Apply get_last_5_venue to compute venue win rates for each row\n",
    "    venue_winrates = games_subset.apply(\n",
    "        lambda row: pd.Series(\n",
    "            get_last_5_venue(row['Match_id'], row['Home.Team'], row['Away.Team'], games)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Assign column names\n",
    "    venue_winrates.columns = ['HomeVenueWinRate', 'AwayVenueWinRate']\n",
    "\n",
    "    # Add the new columns to the subset\n",
    "    games_subset[['HomeVenueWinRate', 'AwayVenueWinRate']] = venue_winrates\n",
    "    games_subset['HomeNetVenueWinrate'] = games_subset['HomeVenueWinRate'] - games_subset['AwayVenueWinRate']\n",
    "    games_subset['AwayNetVenueWinrate'] = games_subset['AwayVenueWinRate'] - games_subset['HomeVenueWinRate']\n",
    "    \n",
    "    return games_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bba9af94-ee36-45dd-b612-f50f15b3ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = add_venue_columns(games, list(range(2020, 2026)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f717f-9304-496f-a0c9-e13bfc3b2a11",
   "metadata": {},
   "source": [
    "I will test if a team’s net venue win rate predicts wins using point-biserial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "671b1489-338a-482b-b3c8-c990f05b5896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.21200451497394496, p-value: 2.0396870829634065e-13\n"
     ]
    }
   ],
   "source": [
    "# Compute the point-biserial correlation between winning at home (binary)\n",
    "# and the net venue win rate (continuous) to see if higher venue advantage predicts home wins\n",
    "corr, p_val = pointbiserialr(venues['HomeWin'], venues['HomeNetVenueWinrate'])\n",
    "\n",
    "# Print the correlation and significance\n",
    "print(f\"Correlation: {corr}, p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f53482-8318-4a25-8ecf-c5d3ae7bc746",
   "metadata": {},
   "source": [
    "The correlation (0.21) is small but highly significant (p ≈ 2×10⁻¹³), confirming that net venue win rate reliably predicts home wins. This justifies using it as a feature.\n",
    "\n",
    "**Winrate Against Opposition**\n",
    "\n",
    "I will investigate how much a team’s recent win rate against a specific opponent predicts the match outcome.\n",
    "\n",
    "This function calculates each team’s win rate over their last 5 head-to-head matchups, providing a feature that captures historical performance between the two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5690a7b4-8862-4a16-a223-b10c3e33ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_5_matchups(matchid, team1, team2, games):\n",
    "\n",
    "    # Filter the games df to have only the matchups between the two teams\n",
    "    team_games = games[((games['Home.Team'] == team1) & (games['Away.Team'] == team2)\n",
    "                       ) | ((games['Home.Team'] == team2) & (games['Away.Team'] == team1))].copy()\n",
    "\n",
    "    # Filter the df to only keep the games prior to the current game\n",
    "    current = team_games.index[team_games['Match_id'] == matchid][0]\n",
    "    team_games = team_games.loc[:current - 1] \n",
    "\n",
    "    # Remove the current game from the df to calculate previous matchup winrate\n",
    "    team_games = team_games.tail(6).iloc[:-1]\n",
    "\n",
    "    # Create new columns containing the wins for each team\n",
    "    team_games['Team1Win'] = ((team_games['Away.Team'] == team1) & (team_games['AwayWin'] == True)\n",
    "                             ) | ((team_games['Home.Team'] == team1) & (team_games['HomeWin'] == True))\n",
    "    team_games['Team2Win'] = ((team_games['Away.Team'] == team2) & (team_games['AwayWin'] == True)\n",
    "                             ) | ((team_games['Home.Team'] == team2) & (team_games['HomeWin'] == True))\n",
    "\n",
    "    # Calculate the winrate from these columns\n",
    "    team1winrate = float(team_games['Team1Win'].astype(int).mean())\n",
    "    team2winrate = float(team_games['Team2Win'].astype(int).mean())\n",
    "    \n",
    "    return [team1winrate, team2winrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97234a34-3d8a-4a74-9022-099a1c1a15b9",
   "metadata": {},
   "source": [
    "This function adds columns for each team’s win rate in their last 5 head-to-head matchups, giving a historical performance feature for each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae1d51b2-ec4f-4c0d-8dbf-a2e3123e5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matchup_columns(games: pd.DataFrame, years) -> pd.DataFrame:\n",
    "    games_subset = games[games['Season'].isin(years)].copy()\n",
    "  \n",
    "    # Apply get_last_5_matchups to compute win rates for each row\n",
    "    matchup_winrates = games_subset.apply(\n",
    "        lambda row: pd.Series(\n",
    "            get_last_5_matchups(row['Match_id'], row['Home.Team'], row['Away.Team'], games)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Assign column names to the result\n",
    "    matchup_winrates.columns = ['HomeLast5MatchupWinRate', 'AwayLast5MatchupWinRate']\n",
    "\n",
    "    # Add the new columns to the original subset\n",
    "    games_subset[['HomeLast5MatchupWinRate', 'AwayLast5MatchupWinRate']] = matchup_winrates\n",
    "    \n",
    "    return games_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1cd45ac-7898-4540-a512-d969eae5cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = add_matchup_columns(games, list(range(2020, 2026)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd71a7c-cefd-4fd1-9c84-a465af60d614",
   "metadata": {},
   "source": [
    "This calculates the correlation between the home team winning and their win rate in the last 5 matchups against the same opponent. A significant positive correlation would suggest that recent head-to-head performance is predictive of the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "0dc564b9-f40b-4a77-94f6-d09de9df2bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.10489207177667467, p-value: 0.0003143633961565997\n"
     ]
    }
   ],
   "source": [
    "# Calculate the point-biserial correlation between HomeWin (binary) \n",
    "# and HomeLast5MatchupWinRate (continuous)\n",
    "corr, p_val = pointbiserialr(matchups['HomeWin'],\n",
    "                             matchups['HomeLast5MatchupWinRate'])\n",
    "\n",
    "# Print the correlation coefficient and p-value\n",
    "print(f\"Correlation: {corr}, p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139dc8c-7ff7-42cb-9722-0f07b287587a",
   "metadata": {},
   "source": [
    "A team’s winrate in the last five matchups against an opponent shows a weak but statistically significant positive correlation (r = 0.105, p < 0.001) with winning. This suggests recent head-to-head performance slightly predicts wins, so it will be included as a feature in the model.\n",
    "\n",
    "**Team Form**\n",
    "\n",
    "Next, I will examine whether a team’s overall winrate over the last 10 games is a significant predictor of match outcomes.\n",
    "\n",
    "This function calculates a team’s recent form by computing their win rate over the last 10 games, including games from the previous season if needed. It provides a simple measure of current performance to use as a predictive feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "6a540f46-2f14-471e-88c2-d9da4f8a6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_10_form(matchid, team, games):\n",
    "    # Filter all games for the team\n",
    "    team_games = games[(games['Home.Team'] == team) | (games['Away.Team'] == team)].copy()\n",
    "    \n",
    "    # Current match info\n",
    "    current_round = team_games[team_games['Match_id'] == matchid]['Round'].max()\n",
    "    current_year = team_games.loc[team_games['Match_id'] == matchid, 'Season'].values[0]\n",
    "\n",
    "    current_season_rounds = []\n",
    "    remaining_rounds = 0\n",
    "    previous_season_needed = False\n",
    "\n",
    "    # Identify last 10 rounds\n",
    "    for i in range(1, 11):\n",
    "        if current_round - i > 0:\n",
    "            current_season_rounds.append(current_round - i)\n",
    "        else:\n",
    "            previous_season_needed = True\n",
    "            remaining_rounds += 1\n",
    "\n",
    "    # Include previous season if needed\n",
    "    if previous_season_needed and current_year != games['Season'].min():\n",
    "        previous_year = current_year - 1\n",
    "        previous_season = team_games[team_games['Season'] == previous_year]\n",
    "        last_round_prev = previous_season['Round'].max()\n",
    "        previous_season_rounds = [last_round_prev - i for i in range(remaining_rounds)]\n",
    "        team_games = team_games[\n",
    "            ((team_games['Season'] == current_year) & (team_games['Round'].isin(current_season_rounds))) |\n",
    "            ((team_games['Season'] == previous_year) & (team_games['Round'].isin(previous_season_rounds)))\n",
    "        ]\n",
    "    else:\n",
    "        team_games = team_games[(team_games['Season'] == current_year) & (team_games['Round'].isin(current_season_rounds))]\n",
    "\n",
    "    # Calculate winrate\n",
    "    team_games['TeamWin'] = ((team_games['Home.Team'] == team) & (team_games['HomeWin'] == True)) | \\\n",
    "                            ((team_games['Away.Team'] == team) & (team_games['AwayWin'] == True))\n",
    "    return team_games['TeamWin'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781c632-b2c1-4aff-b692-74cdb82f7094",
   "metadata": {},
   "source": [
    "This function adds each team’s win rate over the last 10 games and their net form (home minus away) as features for predicting match outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "07c8fa97-5b99-4d1d-81b8-f6c460420778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_winrate_columns(games: pd.DataFrame, years) -> pd.DataFrame:\n",
    "    games_subset = games[games['Season'].isin(years)].copy()\n",
    "\n",
    "\n",
    "    # Calculate form (win rate in last 10 games)\n",
    "    games_subset['AwayForms'] = games_subset.apply(\n",
    "        lambda row: get_last_10_form(row['Match_id'], row['Away.Team'], games),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    games_subset['HomeForms'] = games_subset.apply(\n",
    "        lambda row: get_last_10_form(row['Match_id'], row['Home.Team'], games),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Net form (away - home, and vice versa)\n",
    "    games_subset['AwayNetForm'] = games_subset['AwayForms'] - games_subset['HomeForms']\n",
    "    games_subset['HomeNetForm'] = games_subset['HomeForms'] - games_subset['AwayForms']\n",
    "\n",
    "    return games_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "4dcdb3df-259f-4a3c-82b3-7337faea44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "winrates = add_winrate_columns(games, list(range(2020, 2026)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d7852-ed07-4783-b1c7-903fa8c9b1bc",
   "metadata": {},
   "source": [
    "I will compute the point-biserial correlation between HomeWin and HomeNetForm (the difference in recent 10-game win rates). It measures how strongly a team’s recent form predicts winning, with the p-value indicating statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "c1ace37d-045a-4901-abcb-daa95335900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.33906149649304457, p-value: 5.0162792780374255e-33\n"
     ]
    }
   ],
   "source": [
    "# Compute point-biserial correlation between binary 'HomeWin' and continuous 'HomeNetForm'\n",
    "corr, p_val = pointbiserialr(winrates['HomeWin'], winrates['HomeNetForm'])\n",
    "\n",
    "# Print correlation and p-value\n",
    "print(f\"Correlation: {corr}, p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9153b2cd-455e-40e8-926c-339025fd0fcb",
   "metadata": {},
   "source": [
    "There is a statistically significant positive correlation between HomeNetForm and HomeWin (r = 0.34, p < 0.001), indicating that teams with better recent form are more likely to win. This variable will be used as a feature in the model.\n",
    "\n",
    "**Days Since Last Game**\n",
    "\n",
    "Next, I will examine whether a team’s net rest time influences performance. Net rest time is defined as the difference in rest days between the two teams:\n",
    "Net Rest Time = Home Team Rest Days − Away Team Rest Days.\n",
    "\n",
    "This function calculates a team’s rest days since their previous match, capped at 30 days; returns 0 for the first game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1ff746a-0d49-4c09-bee4-d371c5bf6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_since_last_game(match_id, team, games):\n",
    "    # Ensure Date is in datetime format\n",
    "    games = games.copy()\n",
    "    games['Date'] = pd.to_datetime(games['Date'])\n",
    "    \n",
    "    # Filter games where team is either Home or Away, sorted by date\n",
    "    team_games = games[\n",
    "        (games['Home.Team'] == team) | (games['Away.Team'] == team)\n",
    "    ].copy().sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Check if any games were found for the team\n",
    "    if team_games.empty:\n",
    "        return None\n",
    "        \n",
    "    # Find the current game\n",
    "    current_game = team_games[team_games['Match_id'] == match_id]\n",
    "    if current_game.empty:\n",
    "        return None\n",
    "        \n",
    "    # Get the index of the current game\n",
    "    current_index = current_game.index[0]\n",
    "    \n",
    "    # If it's the first game, return 0\n",
    "    if current_index == 0:\n",
    "        return 0\n",
    "        \n",
    "    # Get the previous game\n",
    "    previous_game = team_games.iloc[current_index - 1]\n",
    "    \n",
    "    # Calculate days between current and previous game\n",
    "    days_diff = (current_game['Date'].iloc[0] - previous_game['Date']).days\n",
    "    if days_diff > 30:\n",
    "        days_diff = 30\n",
    "    return int(days_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab2ac7-af60-4c18-8cc5-db5b2f368499",
   "metadata": {},
   "source": [
    "This function computes rest-related features for each game in the specified seasons, including days since the last game for home and away teams, as well as net rest differences between the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "41a0d197-723f-4bfc-b3b6-9ab8a780ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_columns(games, years):\n",
    "    # Filter games for the specified years\n",
    "    games_subset = games[games['Season'].isin(years)].copy()\n",
    "    \n",
    "    # Check if subset is empty\n",
    "    if games_subset.empty:\n",
    "        return games_subset\n",
    "    \n",
    "    # Calculate days since last game for home and away teams\n",
    "    games_subset['home_days_since'] = games_subset.apply(\n",
    "        lambda row: days_since_last_game(row['Match_id'], row['Home.Team'], games),\n",
    "        axis=1\n",
    "    )\n",
    "    games_subset['away_days_since'] = games_subset.apply(\n",
    "        lambda row: days_since_last_game(row['Match_id'], row['Away.Team'], games),\n",
    "        axis=1\n",
    "    )\n",
    "    games_subset['away_days_since_net'] = games_subset['away_days_since'] - games_subset['home_days_since']\n",
    "    games_subset['home_days_since_net'] = games_subset['home_days_since'] - games_subset['away_days_since']\n",
    "\n",
    "    return games_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "79aec833-848b-4982-b06c-33884d30bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "daysbetween = add_days_columns(games, list(range(2020, 2026)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5167c7-13f7-4292-9d53-f3496290f9ac",
   "metadata": {},
   "source": [
    "I will compute the point-biserial correlation between HomeWin and home_days_since_net. This measures how strongly the number of days since a team’s last home game predicts winning, with the p-value indicating statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "43dcf197-4d22-4486-81e7-1be7fdae78b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.018117709984109075, p-value: 0.5347981847504221\n"
     ]
    }
   ],
   "source": [
    "# Compute point-biserial correlation between binary target and continuous feature\n",
    "corr, p_val = pointbiserialr(daysbetween['HomeWin'], daysbetween['home_days_since_net'])\n",
    "print(f\"Correlation: {corr}, p-value: {p_val}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d1962-2384-45a1-93da-dfb10740bc9e",
   "metadata": {},
   "source": [
    "The point-biserial correlation between home_days_since_net and HomeWin was near zero (r = 0.018, p = 0.535), indicating no significant linear relationship\n",
    "\n",
    "**Team Ratings**\n",
    "\n",
    "I will calculate team ratings based on the stats of players from the last 10 games, accounting for which players are available or absent, as this can significantly affect game outcomes. Using logistic regression to find the optimal formula for player rating, I will use this formula to quantify each player’s impact and sum these contributions to produce overall offensive and defensive team ratings.\n",
    "\n",
    "This function retrieves the last 10 rounds of statistics for a given team, accounting for missing or returning players, and handling cases where the 10-game window extends into the previous season. It ensures the data reflects only the most recent games relevant to the specified match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d403effc-f5df-4cc0-b419-255ed1d61138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_10_rounds(matchid, team, stats):\n",
    "\n",
    "    if 'Missing_Players' in stats.columns or 'Returning_Players' in stats.columns:\n",
    "        team_stats = stats[(stats['Team'] == team) & \n",
    "        (~stats['Player'].isin(stats['Missing_Players'].iloc[-1])) | \n",
    "        (stats['Player'].isin(stats['Returning_Players'].iloc[-1]))].copy() \n",
    "    else:\n",
    "        team_stats = stats[(stats['Team'] == team)].copy()\n",
    "    #Filters stats to have only the current team\n",
    "    current = team_stats[team_stats['Match_id'] == matchid]['Round'].max() \n",
    "    #Defines current as the most recent round\n",
    "\n",
    "    # This was added for later use in modelling\n",
    "    if matchid == 999999:\n",
    "        last_round_players = team_stats[team_stats['Round'] == current - 1]\n",
    "        last_round_players['Round'] = current\n",
    "        last_round_players['Season'] = team_stats['Season'].values[-1]\n",
    "        last_round_players['Match_id'] = 999999\n",
    "        team_stats = team_stats[team_stats['Match_id'] != 999999]\n",
    "        team_stats = pd.concat([team_stats, last_round_players])\n",
    "        \n",
    "    current_season_rounds = []\n",
    "    remaining_rounds = 0\n",
    "    previous_season = None\n",
    "    #Defines variables for later use\n",
    "    current_year = team_stats.loc[team_stats['Match_id'] == matchid, 'Season'].values[0]\n",
    "    years = [current_year]\n",
    "    #Defines the current season\n",
    "    for i in range(1, 11):\n",
    "        if current-i > -1:\n",
    "            current_season_rounds.append(current-i)\n",
    "        else:\n",
    "            previous_season = True\n",
    "            remaining_rounds += 1\n",
    "            \n",
    "    #Adds the last 10 games from this season to a list\n",
    "    if previous_season and current_year != 2015:\n",
    "        previous_season_rounds = []\n",
    "        previous_year = current_year - 1\n",
    "        previous_season = team_stats[team_stats['Season'] == previous_year]\n",
    "        last_round = previous_season['Round'].max()\n",
    "        for i in range(0, remaining_rounds + 1):\n",
    "            previous_season_rounds.append(last_round-i)\n",
    "        years = [current_year, previous_year]\n",
    "    #Adds the games from last season to a list if they are within the last 10 games\n",
    "        team_stats = team_stats[\n",
    "            ((team_stats['Season'] == current_year) & (team_stats['Round'].isin(current_season_rounds))\n",
    "            )\n",
    "            |\n",
    "            ((team_stats['Season'] == previous_year) & (team_stats['Round'].isin(previous_season_rounds))\n",
    "            )\n",
    "        ]\n",
    "        return team_stats\n",
    "    #Returns the rounds played in the current and previous season\n",
    "    else:\n",
    "        team_stats = team_stats[\n",
    "            ((team_stats['Season'] == current_year) & (team_stats['Round'].isin(current_season_rounds))\n",
    "            )\n",
    "        ]\n",
    "        return team_stats\n",
    "    #Returns the rounds played in the current season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557909d-86fc-4e33-aecd-2e62bc0c1987",
   "metadata": {},
   "source": [
    "I will use logistic regression to estimate the optimal coefficients for player statistics, allowing me to derive a formula that represents each player’s rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "0cade93d-eb5b-41bf-aeb1-234a76030075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stat  Coefficient\n",
      "13    G     9.664579\n",
      "0    GA     3.271047\n",
      "20  R50     2.018598\n",
      "17  I50     1.380492\n",
      "18   CL     0.951969\n",
      "Intercept: -0.04825640354149638\n"
     ]
    }
   ],
   "source": [
    "# Full list of stats from your description\n",
    "all_stats = [\n",
    "    'GA', 'CP', 'UP', 'ED', 'DE', 'CM', 'MI5', 'One.Percenters', 'BO',\n",
    "    'K', 'HB', 'D', 'M', 'G', 'B', 'T', 'HO', 'I50', 'CL', 'CG', 'R50',\n",
    "    'FF', 'FA', 'CCL', 'SCL', 'SI', 'MG', 'TO', 'ITC', 'T5'\n",
    "]\n",
    "\n",
    "# Average per team per match\n",
    "avg_stats = stats.groupby(['Match_id', 'Team'], as_index=False)[all_stats].mean()\n",
    "\n",
    "# Merge with match outcome info\n",
    "merged = pd.merge(avg_stats, games[['Match_id', 'Home.Team', 'HomeWin']],\n",
    "                  on='Match_id', how='left')\n",
    "\n",
    "# Flag which row is home team\n",
    "merged['Home.Team'] = (merged['Team'] == merged['Home.Team']).astype(int)\n",
    "\n",
    "# Pivot so we have one row per match with separate home/away columns\n",
    "wide = merged.pivot(index='Match_id', columns='Home.Team', values=all_stats)\n",
    "\n",
    "# Rename columns for clarity\n",
    "wide.columns = [\n",
    "    f\"{stat}_{'Home' if team_flag == 1 else 'Away'}\"\n",
    "    for stat, team_flag in wide.columns\n",
    "]\n",
    "\n",
    "# Compute home - away differences for each stat\n",
    "net_stats = pd.DataFrame({\n",
    "    stat: wide[f\"{stat}_Home\"] - wide[f\"{stat}_Away\"]\n",
    "    for stat in all_stats\n",
    "}, index=wide.index)\n",
    "\n",
    "# Add HomeWin info back\n",
    "home_win = merged.loc[merged['Home.Team'] == 1, ['Match_id', 'HomeWin']].set_index('Match_id')\n",
    "net_stats = net_stats.join(home_win).reset_index()\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = net_stats[all_stats]\n",
    "y = net_stats['HomeWin']\n",
    "\n",
    "# Logistic regression to see how each stat contributes to win probability\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Store coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Stat': all_stats,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(coeff_df.head(5))\n",
    "print(\"Intercept:\", model.intercept_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "d231387b-60c0-4a3c-a4b2-6225535fd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_player_score(matchid, team, stats):\n",
    "    scores_stats = get_last_10_rounds(matchid, team, stats)\n",
    "    #Defines the stats for the last 10 games\n",
    "    \n",
    "    scores_stats = scores_stats.groupby('Player', as_index=False)[all_stats].mean()\n",
    "    \n",
    "    scores_stats['OverallRating'] = (\n",
    "          9.664579  * scores_stats['G'] +\n",
    "          3.271047  * scores_stats['GA'] +\n",
    "          2.018598  * scores_stats['R50'] +\n",
    "          1.380492  * scores_stats['I50'] +\n",
    "          0.951969  * scores_stats['CL'] +\n",
    "          0.868372  * scores_stats['SCL'] +\n",
    "          0.808467  * scores_stats['MI5'] +\n",
    "          0.752320  * scores_stats['SI'] +\n",
    "          0.569299  * scores_stats['One.Percenters'] +\n",
    "          0.428661  * scores_stats['ED'] +\n",
    "          0.308835  * scores_stats['CCL'] +\n",
    "          0.247002  * scores_stats['BO'] +\n",
    "          0.182691  * scores_stats['CP'] +\n",
    "          0.172831  * scores_stats['T5'] +\n",
    "          0.166806  * scores_stats['K'] +\n",
    "          0.127813  * scores_stats['T'] +\n",
    "          0.065054  * scores_stats['FA'] +\n",
    "          0.047224  * scores_stats['MG'] +\n",
    "          0.039307  * scores_stats['ITC'] +\n",
    "          0.017354  * scores_stats['DE'] +\n",
    "         -0.002630  * scores_stats['CM'] +\n",
    "         -0.033898  * scores_stats['HO'] +\n",
    "         -0.112983  * scores_stats['M'] +\n",
    "         -0.147042  * scores_stats['D'] +\n",
    "         -0.307239  * scores_stats['UP'] +\n",
    "         -0.313848  * scores_stats['HB'] +\n",
    "         -0.582394  * scores_stats['FF'] +\n",
    "         -0.783981  * scores_stats['CG'] +\n",
    "         -1.326969  * scores_stats['B'] +\n",
    "         -2.216883  * scores_stats['TO'] +\n",
    "         -0.04825640354149638\n",
    "    )\n",
    "\n",
    "    return scores_stats[['Player', 'OverallRating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "1d293bea-5bc1-45dd-99ae-59c4ab582509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>OverallRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caleb Serong</td>\n",
       "      <td>47.216557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sam Switkowski</td>\n",
       "      <td>39.698521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jordan Clark</td>\n",
       "      <td>37.009085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Luke Jackson</td>\n",
       "      <td>33.430239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Patrick Voss</td>\n",
       "      <td>33.314712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player  OverallRating\n",
       "4     Caleb Serong      47.216557\n",
       "28  Sam Switkowski      39.698521\n",
       "13    Jordan Clark      37.009085\n",
       "18    Luke Jackson      33.430239\n",
       "27    Patrick Voss      33.314712"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_player_score(11357, 'Fremantle', stats).sort_values(by='OverallRating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2bf2c-ccc6-4a1f-9225-fb02e877c884",
   "metadata": {},
   "source": [
    "These results align with expectations based on domain knowledge: Caleb Serong is clearly the standout performer, followed by other key contributors. This supports the accuracy of the rating method, as the rankings are consistent with on-field performance.\n",
    "\n",
    "I will use machine learning to determine the most effective way to calculate team rating. These functions calculate the different rating methods I will test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0967a-30e9-4f18-8777-8dbb6b68c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_18_rating(matchid, team, stats):\n",
    "    player_overall_scores = find_player_score(matchid, team, stats)['OverallRating']\n",
    "    \n",
    "    player_rating = float((player_overall_scores.sort_values(ascending=False)[:18]).sum())\n",
    "    \n",
    "    return [matchid, team, player_rating]\n",
    "\n",
    "def sum_rating(matchid, team, stats):\n",
    "    player_overall_scores = find_player_score(matchid, team, stats)['OverallRating']\n",
    "    \n",
    "    player_rating = float((player_overall_scores.sum()))\n",
    "    \n",
    "    return [matchid, team, player_rating]\n",
    "\n",
    "def mean_18_rating(matchid, team, stats):\n",
    "    player_overall_scores = find_player_score(matchid, team, stats)['OverallRating']\n",
    "    \n",
    "    player_rating = float((player_overall_scores.sort_values(ascending=False)[:18]).mean())\n",
    "    \n",
    "    return [matchid, team, player_rating]\n",
    "\n",
    "def mean_rating(matchid, team, stats):\n",
    "    player_overall_scores = find_player_score(matchid, team, stats)['OverallRating']\n",
    "    \n",
    "    player_rating = float((player_overall_scores.mean()))\n",
    "    \n",
    "    return [matchid, team, player_rating]\n",
    "\n",
    "def std_rating(matchid, team, stats):\n",
    "    player_overall_scores = find_player_score(matchid, team, stats)['OverallRating']\n",
    "    \n",
    "    player_rating = np.std(player_overall_scores)\n",
    "    \n",
    "    return [matchid, team, player_rating]\n",
    "\n",
    "def weighted_rating(matchid, team, stats):\n",
    "    player_overall_scores = find_player_score(matchid, team, stats).sort_values(\n",
    "        by='OverallRating', ascending=False\n",
    "    )\n",
    "\n",
    "    # Create weights: top 5 players get weight 2, rest get weight 1\n",
    "    weights = [2 if i < 5 else 1 for i in range(len(player_overall_scores))]\n",
    "    player_overall_scores['Weights'] = weights\n",
    "\n",
    "    # Weighted average rating\n",
    "    weighted_avg = (player_overall_scores['OverallRating'] * player_overall_scores['Weights']).sum() / sum(weights)\n",
    "\n",
    "    return [matchid, team, float(weighted_avg)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e21e6-4b26-44b5-a389-fa3c6ec73fb4",
   "metadata": {},
   "source": [
    "This function adds the team ratings for a given rating method to a copy of the games dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "3eaddc41-8398-4568-bb2a-df752ae01f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_function_ratings(function, games: pd.DataFrame, stats: pd.DataFrame, years) -> pd.DataFrame:\n",
    "    games_subset = games[games['Season'].isin(years)].copy()\n",
    "\n",
    "    # Compute team ratings once per game/team\n",
    "    games_subset['AwayStats'] = games_subset.apply(\n",
    "        lambda row: function(row['Match_id'], row['Away.Team'], stats),\n",
    "        axis=1\n",
    "    )\n",
    "    games_subset['HomeStats'] = games_subset.apply(\n",
    "        lambda row: function(row['Match_id'], row['Home.Team'], stats),\n",
    "        axis=1\n",
    "    )\n",
    "    # Extract offensive and defensive ratings\n",
    "    games_subset[['AwayTeamRating']] = games_subset['AwayStats'].apply(lambda x: pd.Series(x[2]))\n",
    "    games_subset[['HomeTeamRating']] = games_subset['HomeStats'].apply(lambda x: pd.Series(x[2]))\n",
    "    \n",
    "    # Calculate net rating (away - home)\n",
    "    games_subset['AwayNetRating'] = games_subset['AwayTeamRating'] - games_subset['HomeTeamRating']\n",
    "    games_subset['HomeNetRating'] = games_subset['HomeTeamRating'] - games_subset['AwayTeamRating']\n",
    "    \n",
    "    return games_subset.drop(columns=['HomeStats', 'AwayStats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146c609-3d12-4e11-928b-f8ace5925801",
   "metadata": {},
   "source": [
    "This function adds each of the different team ratings to a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "5b17f971-f8e4-4350-b67f-d1f9b7617744",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_functions = {\n",
    "    \"sum_18\": sum_18_rating,\n",
    "    \"sum\": sum_rating,\n",
    "    \"mean\": mean_rating,\n",
    "    \"mean18\": mean_18_rating,\n",
    "    \"std\": std_rating,\n",
    "    \"weighted\": weighted_rating\n",
    "}\n",
    "\n",
    "def add_all_function_ratings(games: pd.DataFrame, stats: pd.DataFrame, years) -> dict:\n",
    "    results = {}\n",
    "    for name, func in rating_functions.items():\n",
    "        results[name] = add_function_ratings(func, games, stats, years)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868a162-a99f-47ca-9119-15322b3d5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = add_all_function_ratings(games, stats, [2021, 2022, 2023, 2024, 2025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f6f50-d91f-466c-9d97-f7950858a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2fb8e6-e73b-498c-8863-856046cc0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "This function calculates the overall team rating by finding the sum of the top 18 player ratings for the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "4fee8ea3-05ca-4d7f-89b0-16f1450c0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_team_scores(matchid, team, stats):\n",
    "    # Square the individual ratings before taking the mean\n",
    "    player_overall_scores = find_player_off(matchid, team, stats)['OverallRating']\n",
    "    \n",
    "    player_rating = float((player_overall_scores.sort_values(ascending=False)[:18]).sum())\n",
    "    \n",
    "    return [matchid, team, player_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "3fb5d654-a649-4462-b21b-d6990a01ac3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11357, 'Fremantle', 522.7769201372055]"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_team_scores(11357, 'Fremantle', stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c90be5f-a108-45b0-b734-a3ca51f24bbf",
   "metadata": {},
   "source": [
    "This function adds the home and away team ratings into a column in the games dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "efb574bb-b8af-4a18-8293-460a8e103d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_team_and_net_ratings(games: pd.DataFrame, stats: pd.DataFrame, years) -> pd.DataFrame:\n",
    "    games_subset = games[games['Season'].isin(years)].copy()\n",
    "\n",
    "    # Compute team ratings once per game/team\n",
    "    games_subset['AwayStats'] = games_subset.apply(\n",
    "        lambda row: find_team_scores(row['Match_id'], row['Away.Team'], stats),\n",
    "        axis=1\n",
    "    )\n",
    "    games_subset['HomeStats'] = games_subset.apply(\n",
    "        lambda row: find_team_scores(row['Match_id'], row['Home.Team'], stats),\n",
    "        axis=1\n",
    "    )\n",
    "    # Extract offensive and defensive ratings\n",
    "    games_subset[['AwayTeamRating']] = games_subset['AwayStats'].apply(lambda x: pd.Series(x[2]))\n",
    "    games_subset[['HomeTeamRating']] = games_subset['HomeStats'].apply(lambda x: pd.Series(x[2]))\n",
    "    \n",
    "    # Calculate net rating (away - home)\n",
    "    games_subset['AwayNetRating'] = games_subset['AwayTeamRating'] - games_subset['HomeTeamRating']\n",
    "    games_subset['HomeNetRating'] = games_subset['HomeTeamRating'] - games_subset['AwayTeamRating']\n",
    "    \n",
    "    return games_subset.drop(columns=['HomeStats', 'AwayStats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e269de5a-c9a2-4440-8c80-7a38f91aa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = add_team_and_net_ratings(games, stats, list(range(2020, 2026)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d38fd-2ad5-4193-a6f9-437e7834d18f",
   "metadata": {},
   "source": [
    "I'll calculate the point-biserial now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "1446aab6-5c2a-4fc7-8459-3fa1c5e97984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.27338555605300285, p-value: 1.3265290713182506e-21\n"
     ]
    }
   ],
   "source": [
    "# Compute point-biserial correlation between binary target and continuous feature\n",
    "corr, p_val = pointbiserialr(ratings['HomeWin'],\n",
    "                             ratings['HomeNetRating'])\n",
    "print(f\"Correlation: {corr}, p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9865cb6-84bb-49b5-84ed-a59c157329b2",
   "metadata": {},
   "source": [
    "The correlation is 0.273 (p < 0.001), indicating a highly significant relationship. This feature will therefore be included in the model.\n",
    "\n",
    "**Elo Rating**\n",
    "\n",
    "Next, I will calculate Elo ratings for each team. Elo is a dynamic rating system that updates after each game, increasing a team’s rating when it wins (especially against stronger opponents) and decreasing it when it loses. This provides a continuously updated measure of team strength throughout the season.\n",
    "\n",
    "This function calculates the elo ratings for both home and away for a specific game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "5a26cbdc-90a9-455a-a412-98b5e7f15f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elo_ratings(games: pd.DataFrame, base_elo: int = 1500, k: int = 40) -> pd.DataFrame:\n",
    "    # Sort by time\n",
    "    df = games.sort_values(by=['Season', 'Date', 'Time']).copy()\n",
    "\n",
    "    # Elo dictionary\n",
    "    elo_ratings = {}\n",
    "    home_elos, away_elos = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        home, away = row['Home.Team'], row['Away.Team']\n",
    "        margin = abs(row['Home.Points'] - row['Away.Points'])\n",
    "\n",
    "        # Get ratings\n",
    "        home_elo = elo_ratings.get(home, base_elo)\n",
    "        away_elo = elo_ratings.get(away, base_elo)\n",
    "\n",
    "        # Expected outcome\n",
    "        expected_home = 1 / (1 + 10 ** ((away_elo - home_elo) / 400))\n",
    "        expected_away = 1 - expected_home\n",
    "\n",
    "        # Actual result\n",
    "        home_score = 1 if row['HomeWin'] == 1 else 0\n",
    "        away_score = 1 if row['AwayWin'] == 1 else 0\n",
    "\n",
    "        # Margin of Victory Multiplier\n",
    "        mov_mult = np.log(margin + 1) * (2.2 / ((home_elo - away_elo) * 0.001 + 2.2))\n",
    "\n",
    "        # Update Elo ratings\n",
    "        elo_ratings[home] = home_elo + k * mov_mult * (home_score - expected_home)\n",
    "        elo_ratings[away] = away_elo + k * mov_mult * (away_score - expected_away)\n",
    "\n",
    "        # Save pre-game Elo\n",
    "        home_elos.append(home_elo)\n",
    "        away_elos.append(away_elo)\n",
    "\n",
    "    # Add Elo values to df\n",
    "    df['HomeElo'] = home_elos\n",
    "    df['AwayElo'] = away_elos\n",
    "    df['NetHomeElo'] = df['HomeElo'] - df['AwayElo']\n",
    "    df['NetAwayElo'] = -df['NetHomeElo']\n",
    "\n",
    "    return df[['Match_id', 'HomeElo', 'AwayElo', 'NetAwayElo', 'NetHomeElo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2f450ef8-6e54-4a6d-b0e9-ced49d3be76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elos = add_elo_ratings(games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff46fa-1d90-4844-9c2f-e74996bd8b01",
   "metadata": {},
   "source": [
    "Now I'll calculate the point-biserial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5a9eccd6-5dbd-4552-b103-df68d1b238d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.37726036233483995, p-value: 1.0969283381856207e-75\n"
     ]
    }
   ],
   "source": [
    "# Compute point-biserial correlation between binary target and continuous feature\n",
    "merged = pd.merge(games, elos, on='Match_id', how='left')\n",
    "corr, p_val = pointbiserialr(merged['HomeWin'],\n",
    "                             merged['NetHomeElo'])\n",
    "print(f\"Correlation: {corr}, p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51294f-7b8e-42b9-a992-6e7bc3c0ecda",
   "metadata": {},
   "source": [
    "The correlation is 0.377 (p < 0.001), showing a strong and highly significant relationship. This variable will therefore be included as a feature in the model.\n",
    "\n",
    "# 2. Feature Engineering \n",
    "\n",
    "The features being used in modelling include:\n",
    "- Winrate at venue\n",
    "- Winrate against opposition\n",
    "- Overall winrate\n",
    "- Team rating\n",
    "- Elo rating\n",
    "\n",
    "Since I created functions for engineering all the features, I can simply call them all together to create my feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "4c0f3f8d-17cc-4ba5-a70c-054a09fbef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_features(games: pd.DataFrame, stats: pd.DataFrame, years: list) -> pd.DataFrame:\n",
    "    # Compute all features on full history\n",
    "    ratings_df = add_team_and_net_ratings(games, stats, years)\n",
    "    forms_df = add_winrate_columns(games, years)\n",
    "    matchups_df = add_matchup_columns(games, years)\n",
    "    venues_df = add_venue_columns(games, years)\n",
    "    elo_df = add_elo_ratings(games) \n",
    "    days_df = add_days_columns(games, years)\n",
    "    # Filter the final set of rows by year\n",
    "    filtered_games = games[games['Season'].isin(years)].copy()\n",
    "    # Merge only the needed columns from feature sets\n",
    "    filtered_games = filtered_games.merge(\n",
    "        ratings_df[['Match_id', 'HomeTeamRating', 'AwayTeamRating', 'HomeNetRating']],\n",
    "        on='Match_id', how='left'\n",
    "    )\n",
    "    filtered_games = filtered_games.merge(\n",
    "        forms_df[['Match_id', 'HomeForms', 'AwayForms', 'HomeNetForm']],\n",
    "        on='Match_id', how='left'\n",
    "    )\n",
    "    filtered_games = filtered_games.merge(\n",
    "        matchups_df[['Match_id', 'HomeLast5MatchupWinRate', 'AwayLast5MatchupWinRate']],\n",
    "        on='Match_id', how='left'\n",
    "    )\n",
    "    filtered_games = filtered_games.merge(\n",
    "        venues_df[['Match_id', 'HomeVenueWinRate', 'AwayVenueWinRate', 'HomeNetVenueWinrate']],\n",
    "        on='Match_id', how='left'\n",
    "    )\n",
    "    filtered_games = filtered_games.merge(\n",
    "        elo_df[['Match_id', 'HomeElo', 'AwayElo', 'NetHomeElo', 'NetAwayElo']],\n",
    "        on='Match_id', how='left'\n",
    "    )\n",
    "    filtered_games = filtered_games.merge(\n",
    "        days_df[['Match_id', 'home_days_since', 'away_days_since', 'home_days_since_net']],\n",
    "        on='Match_id', how='left')\n",
    "    \n",
    "    # Select final columns\n",
    "    final = filtered_games[[\n",
    "        'Match_id', 'Season', 'Home.Team', 'Away.Team',\n",
    "        'Home.Points', 'Away.Points',\n",
    "        'HomeTeamRating', 'AwayTeamRating',\n",
    "        'HomeNetRating',\n",
    "        'HomeForms', 'AwayForms',\n",
    "        'HomeNetForm',\n",
    "        'HomeLast5MatchupWinRate', 'AwayLast5MatchupWinRate',\n",
    "        'HomeVenueWinRate', 'AwayVenueWinRate', \n",
    "        'HomeNetVenueWinrate',\n",
    "        'HomeElo', 'AwayElo',\n",
    "        'NetHomeElo',\n",
    "        'home_days_since', 'away_days_since',\n",
    "        'home_days_since_net',\n",
    "        'HomeWin', 'AwayWin'\n",
    "    ]]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "6e9e7527-82c8-415f-a240-25b02c852aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = add_all_features(games, stats, list(range(2022, 2026)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "27eed96d-5029-4c1f-833e-f153213bf627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_id</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home.Team</th>\n",
       "      <th>Away.Team</th>\n",
       "      <th>Home.Points</th>\n",
       "      <th>Away.Points</th>\n",
       "      <th>HomeTeamRating</th>\n",
       "      <th>AwayTeamRating</th>\n",
       "      <th>HomeNetRating</th>\n",
       "      <th>HomeForms</th>\n",
       "      <th>...</th>\n",
       "      <th>AwayVenueWinRate</th>\n",
       "      <th>HomeNetVenueWinrate</th>\n",
       "      <th>HomeElo</th>\n",
       "      <th>AwayElo</th>\n",
       "      <th>NetHomeElo</th>\n",
       "      <th>home_days_since</th>\n",
       "      <th>away_days_since</th>\n",
       "      <th>home_days_since_net</th>\n",
       "      <th>HomeWin</th>\n",
       "      <th>AwayWin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10544</td>\n",
       "      <td>2022</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Western Bulldogs</td>\n",
       "      <td>97</td>\n",
       "      <td>71</td>\n",
       "      <td>567.957994</td>\n",
       "      <td>536.284633</td>\n",
       "      <td>31.673362</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1972.914420</td>\n",
       "      <td>1731.034162</td>\n",
       "      <td>241.880258</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10545</td>\n",
       "      <td>2022</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>499.354026</td>\n",
       "      <td>481.195073</td>\n",
       "      <td>18.158953</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1334.536860</td>\n",
       "      <td>1441.948767</td>\n",
       "      <td>-107.411908</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10546</td>\n",
       "      <td>2022</td>\n",
       "      <td>St Kilda</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>85</td>\n",
       "      <td>102</td>\n",
       "      <td>498.042676</td>\n",
       "      <td>442.549737</td>\n",
       "      <td>55.492939</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>1592.247303</td>\n",
       "      <td>1281.063109</td>\n",
       "      <td>311.184193</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10547</td>\n",
       "      <td>2022</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>Essendon</td>\n",
       "      <td>138</td>\n",
       "      <td>72</td>\n",
       "      <td>524.892707</td>\n",
       "      <td>513.073510</td>\n",
       "      <td>11.819197</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1700.579891</td>\n",
       "      <td>1507.296026</td>\n",
       "      <td>193.283865</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10548</td>\n",
       "      <td>2022</td>\n",
       "      <td>GWS</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>92</td>\n",
       "      <td>112</td>\n",
       "      <td>547.933998</td>\n",
       "      <td>564.595405</td>\n",
       "      <td>-16.661406</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1606.239818</td>\n",
       "      <td>1623.081699</td>\n",
       "      <td>-16.841881</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_id  Season  Home.Team         Away.Team  Home.Points  Away.Points  \\\n",
       "0     10544    2022  Melbourne  Western Bulldogs           97           71   \n",
       "1     10545    2022    Carlton          Richmond          101           76   \n",
       "2     10546    2022   St Kilda       Collingwood           85          102   \n",
       "3     10547    2022    Geelong          Essendon          138           72   \n",
       "4     10548    2022        GWS            Sydney           92          112   \n",
       "\n",
       "   HomeTeamRating  AwayTeamRating  HomeNetRating  HomeForms  ...  \\\n",
       "0      567.957994      536.284633      31.673362   0.875000  ...   \n",
       "1      499.354026      481.195073      18.158953   0.400000  ...   \n",
       "2      498.042676      442.549737      55.492939   0.555556  ...   \n",
       "3      524.892707      513.073510      11.819197   0.555556  ...   \n",
       "4      547.933998      564.595405     -16.661406   0.555556  ...   \n",
       "\n",
       "   AwayVenueWinRate  HomeNetVenueWinrate      HomeElo      AwayElo  \\\n",
       "0               0.4                  0.0  1972.914420  1731.034162   \n",
       "1               0.2                  0.2  1334.536860  1441.948767   \n",
       "2               0.8                 -0.8  1592.247303  1281.063109   \n",
       "3               0.2                  0.4  1700.579891  1507.296026   \n",
       "4               0.4                  0.6  1606.239818  1623.081699   \n",
       "\n",
       "   NetHomeElo  home_days_since  away_days_since  home_days_since_net  HomeWin  \\\n",
       "0  241.880258               30               30                    0        1   \n",
       "1 -107.411908               30               30                    0        1   \n",
       "2  311.184193               30               30                    0        0   \n",
       "3  193.283865               30               30                    0        1   \n",
       "4  -16.841881               30               30                    0        0   \n",
       "\n",
       "   AwayWin  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27758b-4dfa-43ab-b232-9ec817ee96f3",
   "metadata": {},
   "source": [
    "# 3. Modelling\n",
    "\n",
    "The models I will test on this data are:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "4482a691-905e-449d-ac30-89636f87c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final[['HomeTeamRating', 'AwayTeamRating', 'HomeForms', 'AwayForms',\n",
    "           'HomeLast5MatchupWinRate', 'HomeVenueWinRate', 'AwayVenueWinRate',\n",
    "           'HomeElo', 'AwayElo', 'home_days_since', 'away_days_since', \n",
    "           'HomeNetRating', 'NetHomeElo', 'HomeNetForm']]\n",
    "y = final['HomeWin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on training data only\n",
    "X_test = scaler.transform(X_test)        # Apply same scaling to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e68430-eec0-4a00-9d84-385ab48ee769",
   "metadata": {},
   "source": [
    "I will use this function for hyperparameter tuning on each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "270f4392-ffc6-4843-88f1-551466bd31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate_model(estimator, param_grid, X_train, \n",
    "                            y_train, X_test, y_test, model_name=\"Model\"):\n",
    "   # Hyperparameter tuning\n",
    "   random_search = RandomizedSearchCV(\n",
    "       estimator=estimator,\n",
    "       param_distributions=param_grid,\n",
    "       n_iter=20,\n",
    "       cv=5,\n",
    "       scoring='accuracy',\n",
    "       n_jobs=-1,\n",
    "       random_state=42\n",
    "   )\n",
    "   \n",
    "   random_search.fit(X_train, y_train)\n",
    "   best_model = random_search.best_estimator_\n",
    "   best_model.fit(X_train, y_train)\n",
    "   \n",
    "   # Get cross-validated predictions for threshold tuning\n",
    "   probs = cross_val_predict(best_model, X_train, y_train, cv=5, method=\"predict_proba\")[:, 1]\n",
    "   \n",
    "   # Find optimal threshold\n",
    "   best_threshold = 0.5\n",
    "   best_acc = 0\n",
    "   for t in np.linspace(0, 1, 101):\n",
    "       preds = (probs >= t).astype(int)\n",
    "       acc = (preds == y_train).mean()\n",
    "       if acc > best_acc:\n",
    "           best_acc, best_threshold = acc, t\n",
    "   \n",
    "   # Test set predictions\n",
    "   y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "   y_pred = (y_prob >= best_threshold).astype(int)\n",
    "   \n",
    "   # Calculate metrics\n",
    "   accuracy = accuracy_score(y_test, y_pred)\n",
    "   roc_auc = roc_auc_score(y_test, y_prob)\n",
    "   conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "   \n",
    "   # Print results\n",
    "   print(f\"\\n=== {model_name.upper()} RESULTS ===\")\n",
    "   print(\"Best parameters:\", random_search.best_params_)\n",
    "   print(f\"Optimal threshold: {best_threshold:.3f}\")\n",
    "   print(f\"Accuracy: {accuracy:.4f}\")\n",
    "   print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "   print(\"Confusion matrix:\")\n",
    "   print(conf_matrix)\n",
    "   \n",
    "   # Store results\n",
    "   results = {\n",
    "       'best_params': random_search.best_params_,\n",
    "       'threshold': best_threshold,\n",
    "       'accuracy': accuracy,\n",
    "       'roc_auc': roc_auc,\n",
    "       'confusion_matrix': conf_matrix\n",
    "   }\n",
    "   \n",
    "   return best_model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a99f0-38e0-47bb-9129-14afec4c021d",
   "metadata": {},
   "source": [
    "I will use this function to evaluate the cv accuracy of the models with the tuned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "f082aa75-56bd-4c6d-86fa-42924199ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_threshold(model, X_train, y_train, \n",
    "                                  X_test, y_test, model_name=\"Model\"):\n",
    "   # Fit the model\n",
    "   model.fit(X_train, y_train)\n",
    "   \n",
    "   # Get cross-validated predictions\n",
    "   probs = cross_val_predict(model, X_train, y_train, cv=5, method=\"predict_proba\")[:, 1]\n",
    "   \n",
    "   # Find optimal threshold\n",
    "   best_threshold = 0.5\n",
    "   best_acc = 0\n",
    "   for t in np.linspace(0, 1, 101):\n",
    "       preds = (probs >= t).astype(int)\n",
    "       acc = (preds == y_train).mean()\n",
    "       if acc > best_acc:\n",
    "           best_acc, best_threshold = acc, t\n",
    "   \n",
    "   print(f\"\\n=== {model_name.upper()} EVALUATION ===\")\n",
    "   print(f\"Optimal threshold: {best_threshold:.3f}\")\n",
    "   print(f\"Cross-validation accuracy with optimal threshold: {best_acc:.4f}\")\n",
    "   \n",
    "   # Apply threshold to cross-validated predictions\n",
    "   cv_preds = (probs >= best_threshold).astype(int)\n",
    "   cv_accuracy = accuracy_score(y_train, cv_preds)\n",
    "   cv_roc_auc = roc_auc_score(y_train, probs)\n",
    "   cv_conf_matrix = confusion_matrix(y_train, cv_preds)\n",
    "   \n",
    "   print(\"\\n=== CROSS-VALIDATION RESULTS ===\")\n",
    "   print(f\"CV Accuracy: {cv_accuracy:.4f}\")\n",
    "   print(f\"CV ROC-AUC: {cv_roc_auc:.4f}\")\n",
    "   print(\"CV Confusion matrix:\")\n",
    "   print(cv_conf_matrix)\n",
    "   \n",
    "   # Test set results\n",
    "   y_prob = model.predict_proba(X_test)[:,1]\n",
    "   y_pred = (y_prob >= best_threshold).astype(int)\n",
    "   \n",
    "   accuracy = accuracy_score(y_test, y_pred)\n",
    "   roc_auc = roc_auc_score(y_test, y_prob)\n",
    "   conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "   \n",
    "   print(\"\\n=== TEST SET RESULTS ===\")\n",
    "   print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "   print(f\"Test ROC-AUC: {roc_auc:.4f}\")\n",
    "   print(\"Test Confusion matrix:\")\n",
    "   print(conf_matrix)\n",
    "   \n",
    "   print(\"\\n=== COMPARISON ===\")\n",
    "   print(f\"CV vs Test Accuracy: {cv_accuracy:.4f} vs {accuracy:.4f}\")\n",
    "   print(f\"Difference: {abs(cv_accuracy - accuracy):.4f}\")\n",
    "   \n",
    "   # Store results\n",
    "   results = {\n",
    "       'threshold': best_threshold,\n",
    "       'cv_accuracy': cv_accuracy,\n",
    "       'cv_roc_auc': cv_roc_auc,\n",
    "       'cv_confusion_matrix': cv_conf_matrix,\n",
    "       'test_accuracy': accuracy,\n",
    "       'test_roc_auc': roc_auc,\n",
    "       'test_confusion_matrix': conf_matrix,\n",
    "       'accuracy_difference': abs(cv_accuracy - accuracy)\n",
    "   }\n",
    "   return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce90fa5-6529-46ce-ba01-019f49ed384d",
   "metadata": {},
   "source": [
    "I will use this function to rate the importance of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "7a43de35-8109-41fc-b24d-046c9e51a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance_and_select(model, X_train, X_test, y_train, y_test, feature_names, top_k=8, print_results=True):\n",
    "    # Convert to DataFrame with proper column names\n",
    "    X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "    X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "    \n",
    "    # Get feature importance based on model type\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Tree-based models (RandomForest, GradientBoosting, etc.)\n",
    "        feature_importance = model.feature_importances_\n",
    "        importance_type = \"Feature Importance\"\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # Linear models (LogisticRegression, SVM, etc.)\n",
    "        feature_importance = np.abs(model.coef_[0])  # Use absolute values of coefficients\n",
    "        importance_type = \"Coefficient Magnitude\"\n",
    "    else:\n",
    "        raise ValueError(f\"Model {type(model).__name__} doesn't support feature importance extraction\")\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    if print_results:\n",
    "        print(f\"{importance_type} Ranking:\")\n",
    "        print(importance_df)\n",
    "    \n",
    "    # Select top features\n",
    "    top_features = importance_df.head(top_k)['feature'].tolist()\n",
    "    X_train_selected = X_train_df[top_features]\n",
    "    X_test_selected = X_test_df[top_features]\n",
    "    \n",
    "    if print_results:\n",
    "        print(f\"\\nSelected top {top_k} features:\")\n",
    "        print(top_features)\n",
    "    \n",
    "    # Train model with selected features\n",
    "    selected_model = model.__class__(**model.get_params())\n",
    "    selected_model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Get cross-validated predictions for threshold optimization\n",
    "    probs = cross_val_predict(selected_model, X_train_selected, y_train, cv=5, method=\"predict_proba\")[:, 1]\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    best_threshold = 0.5\n",
    "    best_acc = 0\n",
    "    for t in np.linspace(0, 1, 101):\n",
    "        preds = (probs >= t).astype(int)\n",
    "        acc = (preds == y_train).mean()\n",
    "        if acc > best_acc:\n",
    "            best_acc, best_threshold = acc, t\n",
    "    \n",
    "    # Get cross-validation accuracy with selected features and optimal threshold\n",
    "    cv_preds = (probs >= best_threshold).astype(int)\n",
    "    cv_accuracy = accuracy_score(y_train, cv_preds)\n",
    "    \n",
    "    # Test on holdout set with optimal threshold\n",
    "    y_prob_selected = selected_model.predict_proba(X_test_selected)[:, 1]\n",
    "    y_pred_selected = (y_prob_selected >= best_threshold).astype(int)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_selected)\n",
    "    \n",
    "    if print_results:\n",
    "        print(f\"\\nOptimal threshold: {best_threshold:.3f}\")\n",
    "        print(f\"CV Accuracy with top {top_k} features and optimal threshold: {cv_accuracy:.4f}\")\n",
    "        print(f\"Test Accuracy with top {top_k} features and optimal threshold: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    results = {\n",
    "        'cv_accuracy': cv_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'optimal_threshold': best_threshold,\n",
    "        'selected_features': top_features,\n",
    "        'accuracy_difference': abs(cv_accuracy - test_accuracy)\n",
    "    }\n",
    "    \n",
    "    return X_train_selected, X_test_selected, importance_df, top_features, selected_model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d98b8-5110-42d8-af0a-411486515f7b",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "fe361066-1c4b-4313-bd35-c825f926ee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7407407407407407\n",
      "ROC-AUC: 0.7603254067584481\n",
      "Confusion matrix:\n",
      " [[48 20]\n",
      " [22 72]]\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities and classes\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:,1]  # probability for class 1\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e58fc1-537e-4cf5-95e9-df3dccbdbe57",
   "metadata": {},
   "source": [
    "Decent. I will tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "7aeb60c4-4656-4333-a043-b20c7798997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOGISTIC REGRESSION RESULTS ===\n",
      "Best parameters: {'solver': 'saga', 'penalty': 'elasticnet', 'max_iter': 1000, 'l1_ratio': 0.3, 'class_weight': 'balanced', 'C': 0.1}\n",
      "Optimal threshold: 0.370\n",
      "Accuracy: 0.6914\n",
      "ROC-AUC: 0.7680\n",
      "Confusion matrix:\n",
      "[[30 38]\n",
      " [12 82]]\n"
     ]
    }
   ],
   "source": [
    "log_param_grid = [\n",
    "   # L1 penalty combinations\n",
    "   {\n",
    "       'penalty': ['l1'],\n",
    "       'solver': ['liblinear', 'saga'],\n",
    "       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "       'max_iter': [1000, 2000],\n",
    "       'class_weight': [None, 'balanced']\n",
    "   },\n",
    "   # L2 penalty combinations  \n",
    "   {\n",
    "       'penalty': ['l2'],\n",
    "       'solver': ['liblinear', 'lbfgs', 'newton-cg', 'saga'],\n",
    "       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "       'max_iter': [1000, 2000],\n",
    "       'class_weight': [None, 'balanced']\n",
    "   },\n",
    "   # Elasticnet penalty\n",
    "   {\n",
    "       'penalty': ['elasticnet'],\n",
    "       'solver': ['saga'],\n",
    "       'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "       'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "       'max_iter': [1000, 2000],\n",
    "       'class_weight': [None, 'balanced']\n",
    "   },\n",
    "   # No penalty\n",
    "   {\n",
    "       'penalty': [None],\n",
    "       'solver': ['lbfgs', 'newton-cg', 'saga'],\n",
    "       'max_iter': [1000, 2000],\n",
    "       'class_weight': [None, 'balanced']\n",
    "   }\n",
    "]\n",
    "\n",
    "best_log, log_results = tune_and_evaluate_model(LogisticRegression(random_state=42), log_param_grid, X_train, \n",
    "                            y_train, X_test, y_test, model_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "1c26d3b6-f392-4a29-832c-7c16a3d75636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOGISTIC REGRESSION EVALUATION ===\n",
      "Optimal threshold: 0.490\n",
      "Cross-validation accuracy with optimal threshold: 0.6667\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.6667\n",
      "CV ROC-AUC: 0.7336\n",
      "CV Confusion matrix:\n",
      "[[238 134]\n",
      " [114 258]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.7407\n",
      "Test ROC-AUC: 0.7650\n",
      "Test Confusion matrix:\n",
      "[[46 22]\n",
      " [20 74]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.6667 vs 0.7407\n",
      "Difference: 0.0741\n"
     ]
    }
   ],
   "source": [
    "log_cv = evaluate_model_with_threshold(best_log, X_train, y_train, X_test, y_test, model_name=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6068f6-bbbb-4d78-b7ad-ff79a0c4a770",
   "metadata": {},
   "source": [
    "Kinda bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d5f4d-c7e6-4520-a7ca-c06df5dd1031",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "c364fb37-8b9d-45b2-8f1f-1c5ddc63a461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.691358024691358\n",
      "ROC-AUC: 0.717459324155194\n",
      "Confusion matrix:\n",
      " [[43 25]\n",
      " [25 69]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_depth=None, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d924152-816a-45b5-a4e6-c312ada97b93",
   "metadata": {},
   "source": [
    "This is poor. I will tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "16cc3467-3091-4e0b-a134-e44c0a1dda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RANDOM FOREST RESULTS ===\n",
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Optimal threshold: 0.450\n",
      "Accuracy: 0.6605\n",
      "ROC-AUC: 0.7366\n",
      "Confusion matrix:\n",
      "[[35 33]\n",
      " [22 72]]\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "   'n_estimators': [500, 1000],        # number of trees\n",
    "   'max_depth': [None, 5, 10, 20],         # maximum depth of each tree\n",
    "   'min_samples_split': [2, 5, 10],        # minimum samples to split a node\n",
    "   'min_samples_leaf': [1, 2, 4],          # minimum samples at a leaf node\n",
    "   'max_features': [None, 'sqrt', 'log2']  # number of features to consider at each split\n",
    "}\n",
    "\n",
    "best_rf, rf_results = tune_and_evaluate_model(RandomForestClassifier(random_state=42), \n",
    "                                              rf_param_grid, X_train, y_train, X_test, y_test, \n",
    "                                              \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "fd202647-01cb-46e2-acb9-0f0c3fd5b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RANDOM FOREST EVALUATION ===\n",
      "Optimal threshold: 0.480\n",
      "Cross-validation accuracy with optimal threshold: 0.7177\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.7177\n",
      "CV ROC-AUC: 0.7787\n",
      "CV Confusion matrix:\n",
      "[[246 126]\n",
      " [ 84 288]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.6728\n",
      "Test ROC-AUC: 0.7175\n",
      "Test Confusion matrix:\n",
      "[[38 30]\n",
      " [23 71]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.7177 vs 0.6728\n",
      "Difference: 0.0449\n"
     ]
    }
   ],
   "source": [
    "rf_results = evaluate_model_with_threshold(best_rf, X_train, y_train, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "1374e767-0891-4f8a-9abc-37f6290f813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Ranking:\n",
      "                    feature  importance\n",
      "12               NetHomeElo    0.135415\n",
      "7                   HomeElo    0.107665\n",
      "8                   AwayElo    0.098797\n",
      "1            AwayTeamRating    0.088582\n",
      "13              HomeNetForm    0.081478\n",
      "11            HomeNetRating    0.071947\n",
      "0            HomeTeamRating    0.071628\n",
      "3                 AwayForms    0.065715\n",
      "2                 HomeForms    0.058687\n",
      "5          HomeVenueWinRate    0.056708\n",
      "6          AwayVenueWinRate    0.048019\n",
      "4   HomeLast5MatchupWinRate    0.040107\n",
      "10          away_days_since    0.039721\n",
      "9           home_days_since    0.035531\n",
      "\n",
      "Selected top 12 features:\n",
      "['NetHomeElo', 'HomeElo', 'AwayElo', 'AwayTeamRating', 'HomeNetForm', 'HomeNetRating', 'HomeTeamRating', 'AwayForms', 'HomeForms', 'HomeVenueWinRate', 'AwayVenueWinRate', 'HomeLast5MatchupWinRate']\n",
      "\n",
      "Optimal threshold: 0.520\n",
      "CV Accuracy with top 12 features and optimal threshold: 0.7110\n",
      "Test Accuracy with top 12 features and optimal threshold: 0.6420\n",
      "Performance with feature selection: CV=0.7110, Test=0.6420\n",
      "Optimal threshold: 0.520\n",
      "Accuracy difference: 0.0690\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['HomeTeamRating', 'AwayTeamRating', 'HomeForms', 'AwayForms',\n",
    "               'HomeLast5MatchupWinRate', 'HomeVenueWinRate', 'AwayVenueWinRate',\n",
    "               'HomeElo', 'AwayElo', 'home_days_since', 'away_days_since', \n",
    "               'HomeNetRating', 'NetHomeElo', 'HomeNetForm']\n",
    "\n",
    "# Get feature importance and train model with selected features\n",
    "X_train_selected, X_test_selected, importance_df, top_features, selected_rf, results = get_feature_importance_and_select(\n",
    "   best_rf, X_train, X_test, y_train, y_test, feature_names, top_k=12\n",
    ")\n",
    "\n",
    "# Access results\n",
    "print(f\"Performance with feature selection: CV={results['cv_accuracy']:.4f}, Test={results['test_accuracy']:.4f}\")\n",
    "print(f\"Optimal threshold: {results['optimal_threshold']:.3f}\")\n",
    "print(f\"Accuracy difference: {results['accuracy_difference']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51531438-0705-48ce-a4ad-a532cc574c04",
   "metadata": {},
   "source": [
    "14 -  0.7164\n",
    "13 - 0.7151\n",
    "12 - 0.7056\n",
    "So it's clearly going down with less features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd12a1f-2f21-4119-8656-c82b85bf2a11",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "8cdcdb32-4aa5-428c-afe3-6081993bf208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6481481481481481\n",
      "ROC-AUC: 0.6968085106382977\n",
      "Confusion matrix:\n",
      " [[36 32]\n",
      " [25 69]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_prob = gb.predict_proba(X_test)[:,1]\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "c7c0bc53-1d86-4e7d-ad82-f80aa3ef1400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GRADIENT BOOSTING RESULTS ===\n",
      "Best parameters: {'subsample': 0.8, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "Optimal threshold: 0.490\n",
      "Accuracy: 0.6605\n",
      "ROC-AUC: 0.7028\n",
      "Confusion matrix:\n",
      "[[42 26]\n",
      " [29 65]]\n"
     ]
    }
   ],
   "source": [
    "gb_param_grid = {\n",
    "    'n_estimators': [200, 500, 800],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "best_gb, gb_results = tune_and_evaluate_model(GradientBoostingClassifier(random_state=42), \n",
    "                                              gb_param_grid, X_train, y_train, X_test, y_test, \n",
    "                                              \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "5b03a861-6fc4-4325-9562-52161f9914a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GRADIENT BOOSTING EVALUATION ===\n",
      "Optimal threshold: 0.380\n",
      "Cross-validation accuracy with optimal threshold: 0.6720\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.6720\n",
      "CV ROC-AUC: 0.7396\n",
      "CV Confusion matrix:\n",
      "[[220 152]\n",
      " [ 92 280]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.5988\n",
      "Test ROC-AUC: 0.6564\n",
      "Test Confusion matrix:\n",
      "[[31 37]\n",
      " [28 66]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.6720 vs 0.5988\n",
      "Difference: 0.0733\n"
     ]
    }
   ],
   "source": [
    "gb_results = evaluate_model_with_threshold(best_gb, X_train, y_train, X_test, y_test, \"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6e4de-5293-48c9-9928-a916ac8e7950",
   "metadata": {},
   "source": [
    "Decent.\n",
    "\n",
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "e4613977-6d57-4339-a728-2e67e537c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7037037037037037\n",
      "ROC-AUC: 0.7313829787234042\n",
      "Confusion matrix:\n",
      " [[42 26]\n",
      " [22 72]]\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(\n",
    "    kernel='rbf',       # radial basis function kernel\n",
    "    C=1.0,              # regularization parameter\n",
    "    gamma='scale',      # kernel coefficient\n",
    "    probability=True,   # to get predicted probabilities for ROC-AUC\n",
    "    random_state=42,\n",
    "    \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_prob = svm_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "c07d4d32-602d-474b-846d-53bcf54259b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM RESULTS ===\n",
      "Best parameters: {'probability': True, 'kernel': 'rbf', 'gamma': 0.1, 'degree': 2, 'class_weight': None, 'C': 10}\n",
      "Optimal threshold: 0.530\n",
      "Accuracy: 0.6481\n",
      "ROC-AUC: 0.6495\n",
      "Confusion matrix:\n",
      "[[40 28]\n",
      " [29 65]]\n"
     ]
    }
   ],
   "source": [
    "svm_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],          # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],      # Kernel type\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],    # Kernel coefficient (for rbf, poly, sigmoid)\n",
    "    'degree': [2, 3, 4, 5],                              # Degree for polynomial kernel\n",
    "    'class_weight': [None, 'balanced'],                   # Handle class imbalance\n",
    "    'probability': [True]                                 # Enable probability estimates (needed for predict_proba)\n",
    "}\n",
    "\n",
    "# Use your function\n",
    "best_svm, svm_results = tune_and_evaluate_model(\n",
    "    SVC(random_state=42),\n",
    "    svm_param_grid,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    \"SVM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "0fc5e7bc-d55b-41ce-bf71-8e1a85d68719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM EVALUATION ===\n",
      "Optimal threshold: 0.430\n",
      "Cross-validation accuracy with optimal threshold: 0.7137\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.7137\n",
      "CV ROC-AUC: 0.7467\n",
      "CV Confusion matrix:\n",
      "[[229 143]\n",
      " [ 70 302]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.5802\n",
      "Test ROC-AUC: 0.6330\n",
      "Test Confusion matrix:\n",
      "[[26 42]\n",
      " [26 68]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.7137 vs 0.5802\n",
      "Difference: 0.1335\n"
     ]
    }
   ],
   "source": [
    "svm_results = evaluate_model_with_threshold(best_svm, X_train, y_train, X_test, y_test, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "f6add71b-433d-4780-b2e9-883e42f6ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM EVALUATION ===\n",
      "Optimal threshold: 0.530\n",
      "Cross-validation accuracy with optimal threshold: 0.6882\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.6882\n",
      "CV ROC-AUC: 0.7414\n",
      "CV Confusion matrix:\n",
      "[[269 103]\n",
      " [129 243]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.7284\n",
      "Test ROC-AUC: 0.7620\n",
      "Test Confusion matrix:\n",
      "[[50 18]\n",
      " [26 68]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.6882 vs 0.7284\n",
      "Difference: 0.0402\n"
     ]
    }
   ],
   "source": [
    "svm_results = evaluate_model_with_threshold(svm_model, X_train, y_train, X_test, y_test, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49473177-e143-4379-bae5-efd980f8b34f",
   "metadata": {},
   "source": [
    "**Voting Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "5dccbc05-3c18-4c8f-83f7-a13a7a3c6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.6604938271604939\n",
      "Ensemble ROC-AUC: 0.7196495619524406\n",
      "Confusion matrix:\n",
      " [[42 26]\n",
      " [29 65]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained best_gb and best_svm\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_model),\n",
    "        ('gb', best_gb),\n",
    "        ('rf', best_rf),\n",
    "        ('log', best_log)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2, 2, 2],  # give more influence to GB and RF\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# Fit ensemble on the training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_prob = ensemble.predict_proba(X_test)[:, 1]\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Ensemble Accuracy:\", accuracy)\n",
    "print(\"Ensemble ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "67de0215-fd0c-452c-9f1e-f8fcda4f7725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ENSEMBLE EVALUATION ===\n",
      "Optimal threshold: 0.510\n",
      "Cross-validation accuracy with optimal threshold: 0.7016\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.7016\n",
      "CV ROC-AUC: 0.7620\n",
      "CV Confusion matrix:\n",
      "[[259 113]\n",
      " [109 263]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.6728\n",
      "Test ROC-AUC: 0.7196\n",
      "Test Confusion matrix:\n",
      "[[45 23]\n",
      " [30 64]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.7016 vs 0.6728\n",
      "Difference: 0.0288\n"
     ]
    }
   ],
   "source": [
    "ensemble_results = evaluate_model_with_threshold(ensemble, X_train, y_train, X_test, y_test, \"Ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c1bdd-e11c-4143-9ada-c4f3bcf5da2a",
   "metadata": {},
   "source": [
    "**Stacking Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "6ac87f48-008d-47ca-8075-ffb6531c8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.691358024691358\n",
      "Ensemble ROC-AUC: 0.7390488110137672\n",
      "Confusion matrix:\n",
      " [[41 27]\n",
      " [23 71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_model),\n",
    "        ('gb', best_gb),\n",
    "        ('rf', best_rf),\n",
    "        ('log', best_log)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=5,               # or StratifiedKFold\n",
    "    n_jobs=-1,\n",
    "    passthrough=False   # True = include original features with meta-model\n",
    ")\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_prob = stack.predict_proba(X_test)[:, 1]\n",
    "y_pred = stack.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Ensemble Accuracy:\", accuracy)\n",
    "print(\"Ensemble ROC-AUC:\", roc_auc)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "44f8128e-e8d8-49b4-b85a-0b5b2d602d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STACKING EVALUATION ===\n",
      "Optimal threshold: 0.560\n",
      "Cross-validation accuracy with optimal threshold: 0.7016\n",
      "\n",
      "=== CROSS-VALIDATION RESULTS ===\n",
      "CV Accuracy: 0.7016\n",
      "CV ROC-AUC: 0.7665\n",
      "CV Confusion matrix:\n",
      "[[283  89]\n",
      " [133 239]]\n",
      "\n",
      "=== TEST SET RESULTS ===\n",
      "Test Accuracy: 0.6852\n",
      "Test ROC-AUC: 0.7390\n",
      "Test Confusion matrix:\n",
      "[[46 22]\n",
      " [29 65]]\n",
      "\n",
      "=== COMPARISON ===\n",
      "CV vs Test Accuracy: 0.7016 vs 0.6852\n",
      "Difference: 0.0164\n"
     ]
    }
   ],
   "source": [
    "stack_results = evaluate_model_with_threshold(stack, X_train, y_train, X_test, y_test, \"Stacking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97548bc5-b294-406f-9078-ddc3e84f063a",
   "metadata": {},
   "source": [
    "I'm happy with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d430a-8501-42dd-9cd8-736db9616e8c",
   "metadata": {},
   "source": [
    "# 4. Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0cb21b04-9012-42f1-abf5-79643822866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_match(home_team, away_team, venue, season, round_n, date, hmissing_players, hreturning_players, amissing_players, areturning_players, model, feature_data, stats, X_train_columns):\n",
    "    match_dict = {\n",
    "        \"Date\": date,\n",
    "        \"Match_id\": 999999, \n",
    "        \"Season\": season,\n",
    "        \"Home.Team\": home_team,\n",
    "        \"Away.Team\": away_team,\n",
    "        \"Venue\": venue,\n",
    "        \"Round\": round_n,\n",
    "    }\n",
    "    match_df = pd.DataFrame([match_dict])\n",
    "    new_games = pd.concat([games, match_df], ignore_index=True)\n",
    "    stats_df1 = pd.DataFrame([{\"Match_id\": 999999,\n",
    "        \"Season\": season,\n",
    "        \"Team\": home_team,\n",
    "        \"Venue\": venue,\n",
    "        \"Round\": round_n,\n",
    "        \"Missing_Players\": hmissing_players,\n",
    "        \"Returning_Players\": hreturning_players}])                 \n",
    "    stats_df2 = pd.DataFrame([{\"Match_id\": 999999,  \n",
    "        \"Season\": season,\n",
    "        \"Team\": away_team,\n",
    "        \"Venue\": venue,\n",
    "        \"Round\": round_n,\n",
    "        \"Missing_Players\": amissing_players,\n",
    "        \"Returning_Players\": areturning_players}])                \n",
    "    new_stats = pd.concat([stats, stats_df1, stats_df2])\n",
    "    match_features = add_all_features(\n",
    "        new_games,\n",
    "        stats=new_stats,  \n",
    "        years=[season]\n",
    "    ).query(\"Match_id == 999999\")\n",
    "    # Select features same as training\n",
    "    X_new = match_features[X_train_columns]\n",
    "    # Predict\n",
    "    predicted_class = model.predict(X_new)[0]\n",
    "    predicted_proba = model.predict_proba(X_new)[0]\n",
    "    # Build output DataFrame\n",
    "    result_df = match_features.copy()\n",
    "    result_df[\"PredictedWinner\"] = \"Home\" if predicted_class == 0 else \"Away\"\n",
    "    result_df[\"PredictedProb_HomeWin\"] = predicted_proba[0]\n",
    "    result_df[\"PredictedProb_AwayWin\"] = predicted_proba[1]\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6a2752ce-9e05-4e37-826b-bccd0bdcda01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 80\u001b[0m\n\u001b[0;32m     66\u001b[0m     hreturning_players \u001b[38;5;241m=\u001b[39m returning_players_dict\u001b[38;5;241m.\u001b[39mget(home_team, [])\n\u001b[0;32m     67\u001b[0m     areturning_players \u001b[38;5;241m=\u001b[39m returning_players_dict\u001b[38;5;241m.\u001b[39mget(away_team, [])\n\u001b[0;32m     69\u001b[0m     result \u001b[38;5;241m=\u001b[39m predict_match(\n\u001b[0;32m     70\u001b[0m         home_team\u001b[38;5;241m=\u001b[39mhome_team,\n\u001b[0;32m     71\u001b[0m         away_team\u001b[38;5;241m=\u001b[39maway_team,\n\u001b[0;32m     72\u001b[0m         venue\u001b[38;5;241m=\u001b[39mvenue,\n\u001b[0;32m     73\u001b[0m         season\u001b[38;5;241m=\u001b[39mseason,\n\u001b[0;32m     74\u001b[0m         round_n\u001b[38;5;241m=\u001b[39mround_n,\n\u001b[0;32m     75\u001b[0m         date\u001b[38;5;241m=\u001b[39mdate,\n\u001b[0;32m     76\u001b[0m         hmissing_players\u001b[38;5;241m=\u001b[39mhmissing_players,\n\u001b[0;32m     77\u001b[0m         amissing_players\u001b[38;5;241m=\u001b[39mamissing_players,\n\u001b[0;32m     78\u001b[0m         hreturning_players\u001b[38;5;241m=\u001b[39mhreturning_players,\n\u001b[0;32m     79\u001b[0m         areturning_players\u001b[38;5;241m=\u001b[39mareturning_players,\n\u001b[1;32m---> 80\u001b[0m         model\u001b[38;5;241m=\u001b[39mbest_model,\n\u001b[0;32m     81\u001b[0m         feature_data\u001b[38;5;241m=\u001b[39mgames,\n\u001b[0;32m     82\u001b[0m         stats\u001b[38;5;241m=\u001b[39mstats,\n\u001b[0;32m     83\u001b[0m         X_train_columns\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     84\u001b[0m     )\n\u001b[0;32m     85\u001b[0m     all_predictions\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     87\u001b[0m final_predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_predictions, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# List of Round 21, 2025 games\n",
    "round21_games_2025 = [\n",
    "    ['Western Bulldogs', 'GWS', 'Marvel Stadium', 2025, 21, '31-07-2025'],\n",
    "    ['Adelaide', 'Hawthorn', 'Adelaide Oval', 2025, 21, '01-08-2025'],\n",
    "    ['Melbourne', 'West Coast', 'Marvel Stadium', 2025, 21, '01-08-2025'],\n",
    "    ['Gold Coast', 'Richmond', 'People First Stadium', 2025, 21, '02-08-2025'],\n",
    "    ['Sydney', 'Essendon', 'SCG', 2025, 21, '02-08-2025'],\n",
    "    ['Collingwood', 'Brisbane', 'MCG', 2025, 21, '02-08-2025'],\n",
    "    ['St Kilda', 'North Melbourne', 'Marvel Stadium', 2025, 21, '02-08-2025'],\n",
    "    ['Geelong', 'Port Adelaide', 'GMHBA Stadium', 2025, 21, '03-08-2025'],\n",
    "    ['Fremantle', 'Carlton', 'Optus Stadium', 2025, 21, '03-08-2025']\n",
    "]\n",
    "\n",
    "# Assuming hmissing_players and amissing_players are provided or default to empty lists\n",
    "# Example: Use ['Heath Chapman'] for Western Bulldogs as per your earlier query\n",
    "missing_players_dict = {\n",
    "    'Western Bulldogs': ['Heath Chapman'],\n",
    "    'GWS': [],\n",
    "    'Adelaide': [],\n",
    "    'Hawthorn': [],\n",
    "    'Melbourne': [],\n",
    "    'West Coast': [],\n",
    "    'Gold Coast': [],\n",
    "    'Richmond': [],\n",
    "    'Sydney': [],\n",
    "    'Essendon': [],\n",
    "    'Collingwood': [],\n",
    "    'Brisbane': [],\n",
    "    'St Kilda': [],\n",
    "    'North Melbourne': [],\n",
    "    'Geelong': [],\n",
    "    'Port Adelaide': [],\n",
    "    'Fremantle': [],\n",
    "    'Carlton': []\n",
    "}\n",
    "\n",
    "returning_players_dict = {\n",
    "    'Western Bulldogs': [],\n",
    "    'GWS': [],\n",
    "    'Adelaide': [],\n",
    "    'Hawthorn': [],\n",
    "    'Melbourne': [],\n",
    "    'West Coast': [],\n",
    "    'Gold Coast': [],\n",
    "    'Richmond': [],\n",
    "    'Sydney': [],\n",
    "    'Essendon': [],\n",
    "    'Collingwood': [],\n",
    "    'Brisbane': [],\n",
    "    'St Kilda': [],\n",
    "    'North Melbourne': [],\n",
    "    'Geelong': [],\n",
    "    'Port Adelaide': [],\n",
    "    'Fremantle': [],\n",
    "    'Carlton': []\n",
    "}\n",
    "\n",
    "all_predictions = []\n",
    "for game in round21_games_2025:\n",
    "    home_team, away_team, venue, season, round_n, date = game\n",
    "    # Normalize venue name\n",
    "    venue = venue.strip().lower()\n",
    "    # Get missing players (default to empty list if not specified)\n",
    "    hmissing_players = missing_players_dict.get(home_team, [])\n",
    "    amissing_players = missing_players_dict.get(away_team, [])\n",
    "    hreturning_players = returning_players_dict.get(home_team, [])\n",
    "    areturning_players = returning_players_dict.get(away_team, [])\n",
    "    \n",
    "    result = predict_match(\n",
    "        home_team=home_team,\n",
    "        away_team=away_team,\n",
    "        venue=venue,\n",
    "        season=season,\n",
    "        round_n=round_n,\n",
    "        date=date,\n",
    "        hmissing_players=hmissing_players,\n",
    "        amissing_players=amissing_players,\n",
    "        hreturning_players=hreturning_players,\n",
    "        areturning_players=areturning_players,\n",
    "        model=best_model,\n",
    "        feature_data=games,\n",
    "        stats=stats,\n",
    "        X_train_columns=X_train.columns\n",
    "    )\n",
    "    all_predictions.append(result)\n",
    "\n",
    "final_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "print(final_predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82acfb0-1ddf-491a-b8bc-7c37ff65df4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
